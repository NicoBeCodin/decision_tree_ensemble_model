# Decision Tree Models Comparison

## Performance Results

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.564e-04
- Training Time: 0.011 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 1.62%
- matrix_size_y: -0.14%
- p1: 15.37%
- p2: 0.10%
- p3: 96.70%
- p4: -14.70%
- p5: 2.87%
- p6: 5.95%
- p7: -8.23%
- p8: 0.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.564e-04
- Training Time: 0.035 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 1.62%
- matrix_size_y: -0.14%
- p1: 15.37%
- p2: 0.10%
- p3: 96.70%
- p4: -14.70%
- p5: 2.87%
- p6: 5.95%
- p7: -8.23%
- p8: 0.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.990e-04
- Training Time: 0.101 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.21%
- matrix_size_y: -0.32%
- p1: 15.72%
- p2: 0.00%
- p3: 107.23%
- p4: -18.95%
- p5: 0.23%
- p6: 6.58%
- p7: -10.70%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.721e-04
- Training Time: 0.941 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -16.61%
- matrix_size_y: 0.00%
- p1: 4.89%
- p2: 0.00%
- p3: 82.25%
- p4: 8.75%
- p5: 1.54%
- p6: 34.65%
- p7: -15.48%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.721 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.362e-04
- Training Time: 40.764 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -7.87%
- matrix_size_y: 1.08%
- p1: 7.73%
- p2: 0.73%
- p3: 54.98%
- p4: 21.71%
- p5: 3.32%
- p6: 25.79%
- p7: -9.74%
- p8: 2.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.362e-04
- Training Time: 0.207 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -7.87%
- matrix_size_y: 1.08%
- p1: 7.73%
- p2: 0.73%
- p3: 54.98%
- p4: 21.71%
- p5: 3.32%
- p6: 25.79%
- p7: -9.74%
- p8: 2.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.326 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.325 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 1.942 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 10.000

#### Feature Importance
- matrix_size_x: -6.47%
- matrix_size_y: 0.00%
- p1: 9.27%
- p2: 0.22%
- p3: 68.59%
- p4: 5.33%
- p5: 3.12%
- p6: 38.04%
- p7: -17.85%
- p8: -0.24%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 30.238 seconds
- Evaluation Time: 0.061 seconds

#### Model Parameters
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 30.000

#### Feature Importance
- matrix_size_x: 3.39%
- matrix_size_y: 0.27%
- p1: 9.81%
- p2: 0.50%
- p3: 45.30%
- p4: 28.75%
- p5: 5.63%
- p6: 5.55%
- p7: -3.18%
- p8: 3.99%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 28.059 seconds
- Evaluation Time: 0.033 seconds

#### Model Parameters
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 30.000

#### Feature Importance
- matrix_size_x: 2.42%
- matrix_size_y: 0.31%
- p1: 8.41%
- p2: 0.45%
- p3: 45.33%
- p4: 30.31%
- p5: 5.79%
- p6: 5.40%
- p7: -2.70%
- p8: 4.28%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 12443312354.000 seconds
- Evaluation Time: 69183979.000 seconds

#### Model Parameters
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000

#### Feature Importance
- matrix_size_x: 1.04%
- matrix_size_y: 1.82%
- p1: 12.99%
- p2: 1.52%
- p3: 47.80%
- p4: 15.53%
- p5: 4.99%
- p6: 19.75%
- p7: -9.14%
- p8: 3.70%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.176 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 100.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.939 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 30.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: -nan%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 4205149168.000 seconds
- Evaluation Time: 62777107.000 seconds

#### Model Parameters
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.562 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -4.82%
- matrix_size_y: 2.11%
- p1: 7.46%
- p2: 1.12%
- p3: 50.08%
- p4: 20.20%
- p5: 4.48%
- p6: 23.98%
- p7: -7.58%
- p8: 2.98%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.246 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -4.98%
- matrix_size_y: 2.29%
- p1: 7.48%
- p2: 1.11%
- p3: 50.13%
- p4: 20.36%
- p5: 4.41%
- p6: 23.91%
- p7: -7.63%
- p8: 2.92%

---

### Bagging

#### Performance Metrics
- MSE: 4.870e-310
- Training Time: 15.261 seconds
- Evaluation Time: 0.033 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000
- num_threads: 1.000
- use_split_histogram: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.65%
- matrix_size_y: 0.50%
- p1: 3.55%
- p2: 0.51%
- p3: 76.72%
- p4: 6.20%
- p5: 1.76%
- p6: 6.67%
- p7: 1.01%
- p8: 1.43%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.151 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.179 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 4.130 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### Boosting

#### Performance Metrics
- MSE: 4.938e-310
- Training Time: 8.940 seconds
- Evaluation Time: 0.097 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_split_histogram: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Bagging

#### Performance Metrics
- MSE: 5.414e-310
- Training Time: 14.595 seconds
- Evaluation Time: 0.034 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000
- num_threads: 1.000
- use_split_histogram: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.73%
- matrix_size_y: 0.55%
- p1: 3.72%
- p2: 0.56%
- p3: 76.02%
- p4: 6.30%
- p5: 1.60%
- p6: 7.16%
- p7: 0.98%
- p8: 1.38%

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 4.781 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 28.013 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.070
- max_depth: 15.000
- min_data_in_leaf: 5.000
- n_estimators: 75.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 41.016 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- bin_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.070
- max_depth: 15.000
- min_data_in_leaf: 5.000
- n_estimators: 75.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 5.998 seconds
- Evaluation Time: 0.026 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### Boosting

#### Performance Metrics
- MSE: 4.979e-310
- Training Time: 13.032 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_split_histogram: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 7.973 seconds
- Evaluation Time: 0.042 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 511.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 6.212 seconds
- Evaluation Time: 0.030 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.407 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 19.415 seconds
- Evaluation Time: 0.080 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 4.005 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- bin_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 61.596 seconds
- Evaluation Time: 0.056 seconds

#### Model Parameters
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 62.427 seconds
- Evaluation Time: 0.064 seconds

#### Model Parameters
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 62.259 seconds
- Evaluation Time: 0.045 seconds

#### Model Parameters
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### Bagging

#### Performance Metrics
- MSE: 4.676e-310
- Training Time: 13.029 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000
- num_threads: 1.000
- use_split_histogram: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.79%
- matrix_size_y: 0.50%
- p1: 3.46%
- p2: 0.49%
- p3: 76.11%
- p4: 6.15%
- p5: 1.77%
- p6: 7.51%
- p7: 0.88%
- p8: 1.35%

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.054e-310
- Training Time: 43.691 seconds
- Evaluation Time: 0.043 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.012e-310
- Training Time: 42.046 seconds
- Evaluation Time: 0.044 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.104e-310
- Training Time: 40.015 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 4.731e-310
- Training Time: 43.992 seconds
- Evaluation Time: 0.040 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.285e-310
- Training Time: 42.594 seconds
- Evaluation Time: 0.042 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Quantile)

#### Performance Metrics
- MSE: 5.206e-310
- Training Time: 9.560 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- binning_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.050
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 50.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.180 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.175 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### AdvancedGBDT (Quantile)

#### Performance Metrics
- MSE: 4.981e-310
- Training Time: 19.614 seconds
- Evaluation Time: 0.023 seconds

#### Model Parameters
- binning_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.213e-310
- Training Time: 21.001 seconds
- Evaluation Time: 0.022 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 4.729e-310
- Training Time: 23.677 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 4.895e-310
- Training Time: 22.315 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 4.998e-310
- Training Time: 20.415 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Quantile)

#### Performance Metrics
- MSE: 5.020e-310
- Training Time: 21.080 seconds
- Evaluation Time: 0.012 seconds

#### Model Parameters
- binning_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Quantile)

#### Performance Metrics
- MSE: 4.906e-310
- Training Time: 22.340 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- binning_method: 0.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 4.639e-310
- Training Time: 20.067 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.100
- learning_rate: 0.100
- max_depth: 6.000
- min_data_in_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 0.000
- skip_drop_rate: 0.050
- use_dart: 0.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 4.796e-310
- Training Time: 2.135 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

