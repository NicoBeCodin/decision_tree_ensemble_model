# Decision Tree Models Comparison

## Performance Results

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.564e-04
- Training Time: 0.011 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 1.62%
- matrix_size_y: -0.14%
- p1: 15.37%
- p2: 0.10%
- p3: 96.70%
- p4: -14.70%
- p5: 2.87%
- p6: 5.95%
- p7: -8.23%
- p8: 0.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.564e-04
- Training Time: 0.035 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 1.62%
- matrix_size_y: -0.14%
- p1: 15.37%
- p2: 0.10%
- p3: 96.70%
- p4: -14.70%
- p5: 2.87%
- p6: 5.95%
- p7: -8.23%
- p8: 0.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.990e-04
- Training Time: 0.101 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.21%
- matrix_size_y: -0.32%
- p1: 15.72%
- p2: 0.00%
- p3: 107.23%
- p4: -18.95%
- p5: 0.23%
- p6: 6.58%
- p7: -10.70%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.721e-04
- Training Time: 0.941 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -16.61%
- matrix_size_y: 0.00%
- p1: 4.89%
- p2: 0.00%
- p3: 82.25%
- p4: 8.75%
- p5: 1.54%
- p6: 34.65%
- p7: -15.48%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.721 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.362e-04
- Training Time: 40.764 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -7.87%
- matrix_size_y: 1.08%
- p1: 7.73%
- p2: 0.73%
- p3: 54.98%
- p4: 21.71%
- p5: 3.32%
- p6: 25.79%
- p7: -9.74%
- p8: 2.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.362e-04
- Training Time: 0.207 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -7.87%
- matrix_size_y: 1.08%
- p1: 7.73%
- p2: 0.73%
- p3: 54.98%
- p4: 21.71%
- p5: 3.32%
- p6: 25.79%
- p7: -9.74%
- p8: 2.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.326 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.325 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 1.942 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 10.000

#### Feature Importance
- matrix_size_x: -6.47%
- matrix_size_y: 0.00%
- p1: 9.27%
- p2: 0.22%
- p3: 68.59%
- p4: 5.33%
- p5: 3.12%
- p6: 38.04%
- p7: -17.85%
- p8: -0.24%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 30.238 seconds
- Evaluation Time: 0.061 seconds

#### Model Parameters
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 30.000

#### Feature Importance
- matrix_size_x: 3.39%
- matrix_size_y: 0.27%
- p1: 9.81%
- p2: 0.50%
- p3: 45.30%
- p4: 28.75%
- p5: 5.63%
- p6: 5.55%
- p7: -3.18%
- p8: 3.99%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 28.059 seconds
- Evaluation Time: 0.033 seconds

#### Model Parameters
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 30.000

#### Feature Importance
- matrix_size_x: 2.42%
- matrix_size_y: 0.31%
- p1: 8.41%
- p2: 0.45%
- p3: 45.33%
- p4: 30.31%
- p5: 5.79%
- p6: 5.40%
- p7: -2.70%
- p8: 4.28%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 12443312354.000 seconds
- Evaluation Time: 69183979.000 seconds

#### Model Parameters
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000

#### Feature Importance
- matrix_size_x: 1.04%
- matrix_size_y: 1.82%
- p1: 12.99%
- p2: 1.52%
- p3: 47.80%
- p4: 15.53%
- p5: 4.99%
- p6: 19.75%
- p7: -9.14%
- p8: 3.70%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.176 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 100.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.939 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 30.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: -nan%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 4205149168.000 seconds
- Evaluation Time: 62777107.000 seconds

#### Model Parameters
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.562 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -4.82%
- matrix_size_y: 2.11%
- p1: 7.46%
- p2: 1.12%
- p3: 50.08%
- p4: 20.20%
- p5: 4.48%
- p6: 23.98%
- p7: -7.58%
- p8: 2.98%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.246 seconds
- Evaluation Time: 0.002 seconds
### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.289e-310
- Training Time: 1.973 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### Boosting

#### Performance Metrics
- MSE: 5.485e-310
- Training Time: 13.069 seconds
- Evaluation Time: 0.091 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_omp: 0.000
- use_split_histogram: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Bagging

#### Performance Metrics
- MSE: 4.943e-310
- Training Time: 20.258 seconds
- Evaluation Time: 0.052 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000
- num_threads: 1.000
- use_omp: 0.000
- use_split_histogram: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.56%
- matrix_size_y: 0.61%
- p1: 3.31%
- p2: 0.56%
- p3: 76.94%
- p4: 6.62%
- p5: 1.61%
- p6: 6.51%
- p7: 1.07%
- p8: 1.20%

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.005e-310
- Training Time: 1.420 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 8.413e-04
- Training Time: 1.341 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.717e-310
- Training Time: 17.176 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_omp: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.70%
- matrix_size_y: 1.19%
- p1: 7.98%
- p2: 1.06%
- p3: 36.02%
- p4: 20.49%
- p5: 4.67%
- p6: 18.11%
- p7: 2.67%
- p8: 3.10%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.158 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.094e-310
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.150
- learning_rate: 0.050
- max_depth: 15.000
- min_data_leaf: 5.000
- n_estimators: 100.000
- num_bins: 256.000
- num_threads: 8.000
- skip_drop_rate: 0.100
- use_dart: 1.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.255e-310
- Training Time: 0.065 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.693e-310
- Training Time: 0.068 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.217e-310
- Training Time: 0.065 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.165 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.215e-310
- Training Time: 4.905 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.95%
- matrix_size_y: 0.61%
- p1: 3.08%
- p2: 0.09%
- p3: 39.25%
- p4: 27.55%
- p5: 2.30%
- p6: 16.01%
- p7: 5.62%
- p8: 2.52%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.448 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.959e-310
- Training Time: 7.999 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.010
- max_depth: 3.000
- min_data_leaf: 30.000
- n_estimators: 200.000
- num_bins: 500.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.81%
- matrix_size_y: 0.02%
- p1: 1.29%
- p2: 0.00%
- p3: 50.83%
- p4: 31.58%
- p5: 0.16%
- p6: 13.82%
- p7: 1.24%
- p8: 0.24%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.371e-310
- Training Time: 4.972 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.95%
- matrix_size_y: 0.61%
- p1: 3.08%
- p2: 0.09%
- p3: 39.25%
- p4: 27.55%
- p5: 2.30%
- p6: 16.01%
- p7: 5.62%
- p8: 2.52%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.415e-310
- Training Time: 2.390 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 50.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.85%
- matrix_size_y: 0.55%
- p1: 3.12%
- p2: 0.07%
- p3: 41.15%
- p4: 28.16%
- p5: 1.82%
- p6: 15.33%
- p7: 4.74%
- p8: 2.20%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.009e-310
- Training Time: 2.377 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 50.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.85%
- matrix_size_y: 0.55%
- p1: 3.12%
- p2: 0.07%
- p3: 41.15%
- p4: 28.16%
- p5: 1.82%
- p6: 15.33%
- p7: 4.74%
- p8: 2.20%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.175e-310
- Training Time: 7.846 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.731e-310
- Training Time: 8.179 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.503e-310
- Training Time: 8.149 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.639e-310
- Training Time: 0.120 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.964e-310
- Training Time: 6.038 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.136e-310
- Training Time: 1.508 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 1.52%
- matrix_size_y: 3.51%
- p1: 6.37%
- p2: 0.68%
- p3: 26.19%
- p4: 11.36%
- p5: 12.57%
- p6: 20.37%
- p7: 13.64%
- p8: 3.78%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.216e-310
- Training Time: 10.212 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.03%
- matrix_size_y: 0.06%
- p1: 99.40%
- p2: 0.02%
- p3: 0.08%
- p4: 0.11%
- p5: 0.11%
- p6: 0.08%
- p7: 0.03%
- p8: 0.08%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.485e-310
- Training Time: 8.541 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.488e-310
- Training Time: 3.300 seconds
- Evaluation Time: 0.012 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.03%
- matrix_size_y: 0.06%
- p1: 99.40%
- p2: 0.02%
- p3: 0.08%
- p4: 0.11%
- p5: 0.11%
- p6: 0.08%
- p7: 0.03%
- p8: 0.08%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.251e-310
- Training Time: 7.945 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.139e-310
- Training Time: 6.006 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.827e-310
- Training Time: 5.743 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.065 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.324e-310
- Training Time: 27.572 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.39%
- p1: 9.80%
- p2: 0.20%
- p3: 70.11%
- p4: 5.46%
- p5: 4.48%
- p6: 2.22%
- p7: 0.65%
- p8: 1.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.137 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.137 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.104 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.649e-310
- Training Time: 27.683 seconds
- Evaluation Time: 0.117 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.57%
- matrix_size_y: 0.33%
- p1: 9.85%
- p2: 0.22%
- p3: 70.51%
- p4: 5.42%
- p5: 4.05%
- p6: 2.25%
- p7: 0.54%
- p8: 1.26%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.079 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.076 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.069 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.720e-310
- Training Time: 27.441 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.04%
- matrix_size_y: 0.40%
- p1: 9.78%
- p2: 0.23%
- p3: 70.39%
- p4: 5.18%
- p5: 4.56%
- p6: 2.45%
- p7: 0.51%
- p8: 1.46%

---

### Bagging

#### Performance Metrics
- MSE: 5.154e-310
- Training Time: 27.568 seconds
- Evaluation Time: 0.125 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.43%
- matrix_size_y: 0.32%
- p1: 9.81%
- p2: 0.24%
- p3: 70.42%
- p4: 5.60%
- p5: 4.19%
- p6: 2.19%
- p7: 0.54%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.957e-310
- Training Time: 27.625 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.57%
- matrix_size_y: 0.28%
- p1: 9.92%
- p2: 0.26%
- p3: 70.32%
- p4: 5.20%
- p5: 4.19%
- p6: 2.40%
- p7: 0.56%
- p8: 1.31%

---

### Bagging

#### Performance Metrics
- MSE: 5.163e-310
- Training Time: 8.740 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.23%
- matrix_size_y: 0.36%
- p1: 10.01%
- p2: 0.28%
- p3: 70.03%
- p4: 5.58%
- p5: 4.32%
- p6: 2.39%
- p7: 0.62%
- p8: 1.19%

---

### Bagging

#### Performance Metrics
- MSE: 5.038e-310
- Training Time: 8.797 seconds
- Evaluation Time: 0.111 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.24%
- matrix_size_y: 0.34%
- p1: 9.56%
- p2: 0.21%
- p3: 70.81%
- p4: 5.41%
- p5: 4.27%
- p6: 2.23%
- p7: 0.59%
- p8: 1.33%

---

### Bagging

#### Performance Metrics
- MSE: 5.055e-310
- Training Time: 8.828 seconds
- Evaluation Time: 0.118 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.63%
- matrix_size_y: 0.38%
- p1: 9.82%
- p2: 0.26%
- p3: 70.49%
- p4: 5.32%
- p5: 3.99%
- p6: 2.36%
- p7: 0.54%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 5.231e-310
- Training Time: 5.505 seconds
- Evaluation Time: 0.155 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.51%
- matrix_size_y: 0.42%
- p1: 9.76%
- p2: 0.25%
- p3: 70.37%
- p4: 5.29%
- p5: 4.20%
- p6: 2.53%
- p7: 0.57%
- p8: 1.11%

---

### Bagging

#### Performance Metrics
- MSE: 5.284e-310
- Training Time: 5.081 seconds
- Evaluation Time: 0.136 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.26%
- matrix_size_y: 0.35%
- p1: 10.03%
- p2: 0.22%
- p3: 70.43%
- p4: 5.40%
- p5: 3.98%
- p6: 2.32%
- p7: 0.67%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.126e-310
- Training Time: 5.837 seconds
- Evaluation Time: 0.182 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.35%
- p1: 9.72%
- p2: 0.23%
- p3: 70.35%
- p4: 5.46%
- p5: 4.20%
- p6: 2.36%
- p7: 0.56%
- p8: 1.34%

---

### Bagging

#### Performance Metrics
- MSE: 4.894e-310
- Training Time: 5.603 seconds
- Evaluation Time: 0.212 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.46%
- matrix_size_y: 0.37%
- p1: 10.01%
- p2: 0.21%
- p3: 69.89%
- p4: 5.31%
- p5: 4.33%
- p6: 2.57%
- p7: 0.60%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 5.487e-310
- Training Time: 6.396 seconds
- Evaluation Time: 0.197 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.32%
- p1: 9.80%
- p2: 0.24%
- p3: 70.44%
- p4: 5.13%
- p5: 4.58%
- p6: 2.43%
- p7: 0.64%
- p8: 1.28%

---

### Bagging

#### Performance Metrics
- MSE: 4.980e-310
- Training Time: 5.561 seconds
- Evaluation Time: 0.157 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.38%
- p1: 9.82%
- p2: 0.22%
- p3: 70.34%
- p4: 5.37%
- p5: 4.33%
- p6: 2.42%
- p7: 0.66%
- p8: 1.32%

---

### Boosting

#### Performance Metrics
- MSE: 4.828e-310
- Training Time: 3.863 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.136e-310
- Training Time: 3.867 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.099e-310
- Training Time: 3.868 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.390e-310
- Training Time: 2.908 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.403e-310
- Training Time: 2.932 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.030e-310
- Training Time: 2.916 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.868e-310
- Training Time: 2.306 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.033e-310
- Training Time: 2.279 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.858e-310
- Training Time: 2.291 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.146e-310
- Training Time: 2.390 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.342e-310
- Training Time: 2.325 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.053e-310
- Training Time: 2.337 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.173 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.162 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.173 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.185 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.137 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.164 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.154 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.139 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.167 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.155 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.178 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.417e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 132529881563264.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.734e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 128016948595456.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.941e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 131960162898048.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.079e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129120205738112.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.055e-310
- Training Time: 0.020 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140038971001600.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.707e-310
- Training Time: 0.023 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130757104861312.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.816e-310
- Training Time: 5.221 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130875970751232.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.77%
- matrix_size_y: 1.36%
- p1: 7.80%
- p2: 0.80%
- p3: 36.33%
- p4: 21.85%
- p5: 5.40%
- p6: 7.18%
- p7: 4.11%
- p8: 4.39%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.158e-310
- Training Time: 0.029 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129107692841728.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.030 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.031 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.052 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.111e-310
- Training Time: 4.138 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.44%
- matrix_size_y: 0.38%
- p1: 2.90%
- p2: 0.29%
- p3: 77.28%
- p4: 5.27%
- p5: 1.03%
- p6: 9.60%
- p7: 0.61%
- p8: 1.21%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.426e-310
- Training Time: 5.454 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126192787798784.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.90%
- matrix_size_y: 1.45%
- p1: 7.90%
- p2: 0.81%
- p3: 36.15%
- p4: 21.60%
- p5: 5.45%
- p6: 7.04%
- p7: 4.27%
- p8: 4.44%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.786e-310
- Training Time: 5.227 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 128083065507968.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.82%
- matrix_size_y: 1.36%
- p1: 7.87%
- p2: 0.81%
- p3: 36.22%
- p4: 21.81%
- p5: 5.51%
- p6: 6.99%
- p7: 4.13%
- p8: 4.47%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.063e-310
- Training Time: 0.022 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133414955344000.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.063 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.058e-310
- Training Time: 27.557 seconds
- Evaluation Time: 0.113 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.52%
- matrix_size_y: 0.30%
- p1: 9.70%
- p2: 0.20%
- p3: 70.61%
- p4: 5.55%
- p5: 4.19%
- p6: 2.09%
- p7: 0.59%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.727e-310
- Training Time: 27.274 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.76%
- matrix_size_y: 0.34%
- p1: 9.90%
- p2: 0.25%
- p3: 70.38%
- p4: 5.31%
- p5: 3.82%
- p6: 2.39%
- p7: 0.64%
- p8: 1.22%

---

### Bagging

#### Performance Metrics
- MSE: 5.439e-310
- Training Time: 27.349 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.37%
- matrix_size_y: 0.37%
- p1: 9.78%
- p2: 0.23%
- p3: 70.20%
- p4: 5.39%
- p5: 4.56%
- p6: 2.37%
- p7: 0.50%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 4.999e-310
- Training Time: 8.703 seconds
- Evaluation Time: 0.111 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.04%
- matrix_size_y: 0.31%
- p1: 9.59%
- p2: 0.23%
- p3: 70.19%
- p4: 5.41%
- p5: 4.64%
- p6: 2.51%
- p7: 0.58%
- p8: 1.49%

---

### Bagging

#### Performance Metrics
- MSE: 5.466e-310
- Training Time: 8.744 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.50%
- matrix_size_y: 0.32%
- p1: 10.11%
- p2: 0.27%
- p3: 70.26%
- p4: 5.20%
- p5: 4.27%
- p6: 2.27%
- p7: 0.67%
- p8: 1.12%

---

### Bagging

#### Performance Metrics
- MSE: 4.748e-310
- Training Time: 8.835 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.33%
- p1: 9.88%
- p2: 0.25%
- p3: 69.99%
- p4: 5.40%
- p5: 4.34%
- p6: 2.69%
- p7: 0.46%
- p8: 1.21%

---

### Bagging

#### Performance Metrics
- MSE: 4.826e-310
- Training Time: 5.001 seconds
- Evaluation Time: 0.143 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.23%
- matrix_size_y: 0.36%
- p1: 9.81%
- p2: 0.23%
- p3: 70.52%
- p4: 5.34%
- p5: 4.32%
- p6: 2.22%
- p7: 0.66%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.368e-310
- Training Time: 4.908 seconds
- Evaluation Time: 0.134 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.39%
- matrix_size_y: 0.40%
- p1: 9.92%
- p2: 0.25%
- p3: 70.10%
- p4: 5.36%
- p5: 4.09%
- p6: 2.76%
- p7: 0.55%
- p8: 1.19%

---

### Bagging

#### Performance Metrics
- MSE: 4.795e-310
- Training Time: 4.887 seconds
- Evaluation Time: 0.136 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.54%
- matrix_size_y: 0.36%
- p1: 10.00%
- p2: 0.29%
- p3: 70.38%
- p4: 5.19%
- p5: 4.02%
- p6: 2.35%
- p7: 0.60%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 4.694e-310
- Training Time: 5.210 seconds
- Evaluation Time: 0.164 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.47%
- matrix_size_y: 0.40%
- p1: 9.60%
- p2: 0.25%
- p3: 70.22%
- p4: 5.21%
- p5: 4.67%
- p6: 2.23%
- p7: 0.60%
- p8: 1.36%

---

### Bagging

#### Performance Metrics
- MSE: 5.422e-310
- Training Time: 5.055 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.39%
- p1: 9.78%
- p2: 0.24%
- p3: 70.32%
- p4: 5.27%
- p5: 4.25%
- p6: 2.46%
- p7: 0.59%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 4.657e-310
- Training Time: 5.024 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.26%
- matrix_size_y: 0.31%
- p1: 9.80%
- p2: 0.21%
- p3: 70.51%
- p4: 5.52%
- p5: 4.25%
- p6: 2.26%
- p7: 0.63%
- p8: 1.25%

---

### Boosting

#### Performance Metrics
- MSE: 4.807e-310
- Training Time: 3.867 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.186e-310
- Training Time: 3.855 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.798e-310
- Training Time: 3.867 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.470e-310
- Training Time: 2.891 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.083e-310
- Training Time: 2.891 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.397e-310
- Training Time: 2.897 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.794e-310
- Training Time: 2.291 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.490e-310
- Training Time: 2.258 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.934e-310
- Training Time: 2.284 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.269e-310
- Training Time: 2.320 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.846e-310
- Training Time: 2.301 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.680e-310
- Training Time: 2.344 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.171 seconds
- Evaluation Time: 0.027 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.175 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.174 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.157 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.160 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.145 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.204 seconds
- Evaluation Time: 0.012 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.187 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.191 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.221e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125860807904000.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.359e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127059020688128.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.940e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140356652175488.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.390e-310
- Training Time: 0.019 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135992551766784.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.965e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140192399354624.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.473e-310
- Training Time: 0.023 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123336012886144.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.724e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136895459691264.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.922e-310
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137405860350720.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.045e-310
- Training Time: 0.071 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 124280496917248.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.639e-310
- Training Time: 0.782 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138367637764864.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.028 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.045 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.046 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.029e-310
- Training Time: 4.212 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.29%
- matrix_size_y: 0.52%
- p1: 3.61%
- p2: 0.42%
- p3: 75.22%
- p4: 4.79%
- p5: 0.76%
- p6: 11.64%
- p7: 0.81%
- p8: 0.95%

---

### Bagging

#### Performance Metrics
- MSE: 4.664e-310
- Training Time: 4.190 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.24%
- matrix_size_y: 0.26%
- p1: 3.47%
- p2: 0.58%
- p3: 78.26%
- p4: 4.48%
- p5: 1.36%
- p6: 8.57%
- p7: 0.72%
- p8: 1.04%

---

### Bagging

#### Performance Metrics
- MSE: 5.415e-310
- Training Time: 4.192 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.27%
- matrix_size_y: 0.30%
- p1: 3.88%
- p2: 0.56%
- p3: 75.78%
- p4: 5.60%
- p5: 0.83%
- p6: 10.39%
- p7: 0.50%
- p8: 0.89%

---

### Bagging

#### Performance Metrics
- MSE: 4.689e-310
- Training Time: 2.902 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.71%
- matrix_size_y: 0.39%
- p1: 3.71%
- p2: 0.29%
- p3: 77.93%
- p4: 6.33%
- p5: 1.35%
- p6: 5.57%
- p7: 1.31%
- p8: 1.41%

---

### Bagging

#### Performance Metrics
- MSE: 4.809e-310
- Training Time: 2.985 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.67%
- matrix_size_y: 0.42%
- p1: 4.18%
- p2: 0.43%
- p3: 76.66%
- p4: 5.70%
- p5: 1.51%
- p6: 7.31%
- p7: 0.79%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.446e-310
- Training Time: 3.055 seconds
- Evaluation Time: 0.050 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.52%
- matrix_size_y: 0.40%
- p1: 4.38%
- p2: 0.42%
- p3: 78.00%
- p4: 6.49%
- p5: 1.34%
- p6: 5.54%
- p7: 0.83%
- p8: 1.07%

---

### Bagging

#### Performance Metrics
- MSE: 5.286e-310
- Training Time: 3.394 seconds
- Evaluation Time: 0.104 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.70%
- matrix_size_y: 0.38%
- p1: 10.26%
- p2: 0.28%
- p3: 72.34%
- p4: 5.05%
- p5: 3.03%
- p6: 2.59%
- p7: 0.94%
- p8: 1.44%

---

### Bagging

#### Performance Metrics
- MSE: 4.827e-310
- Training Time: 3.544 seconds
- Evaluation Time: 0.117 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.73%
- matrix_size_y: 0.46%
- p1: 10.41%
- p2: 0.28%
- p3: 72.84%
- p4: 4.71%
- p5: 2.86%
- p6: 2.62%
- p7: 0.79%
- p8: 1.29%

---

### Bagging

#### Performance Metrics
- MSE: 5.161e-310
- Training Time: 3.417 seconds
- Evaluation Time: 0.094 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.75%
- matrix_size_y: 0.45%
- p1: 9.76%
- p2: 0.26%
- p3: 72.95%
- p4: 5.19%
- p5: 2.93%
- p6: 2.46%
- p7: 0.85%
- p8: 1.39%

---

### Bagging

#### Performance Metrics
- MSE: 5.267e-310
- Training Time: 5.036 seconds
- Evaluation Time: 0.151 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.44%
- matrix_size_y: 0.37%
- p1: 9.64%
- p2: 0.26%
- p3: 70.47%
- p4: 5.43%
- p5: 4.03%
- p6: 2.44%
- p7: 0.58%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.220e-310
- Training Time: 4.864 seconds
- Evaluation Time: 0.152 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.35%
- matrix_size_y: 0.35%
- p1: 9.65%
- p2: 0.23%
- p3: 70.37%
- p4: 5.62%
- p5: 4.35%
- p6: 2.32%
- p7: 0.52%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 4.734e-310
- Training Time: 4.954 seconds
- Evaluation Time: 0.153 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.24%
- matrix_size_y: 0.32%
- p1: 9.94%
- p2: 0.25%
- p3: 69.95%
- p4: 5.20%
- p5: 4.74%
- p6: 2.49%
- p7: 0.52%
- p8: 1.34%

---

### Boosting

#### Performance Metrics
- MSE: 5.249e-310
- Training Time: 0.516 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.418e-310
- Training Time: 0.515 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.918e-310
- Training Time: 0.515 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.331e-310
- Training Time: 0.827 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.158e-310
- Training Time: 0.831 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.162e-310
- Training Time: 0.824 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.368e-310
- Training Time: 1.539 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 4.663e-310
- Training Time: 1.559 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.339e-310
- Training Time: 1.521 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.123e-310
- Training Time: 2.377 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.107e-310
- Training Time: 2.351 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.684e-310
- Training Time: 2.351 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.053 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.054 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.057 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.094 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.093 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.093 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.128 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.125 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.136 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.159 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.185 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.160 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.848e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125856716360448.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.711e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138530554581120.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.440e-310
- Training Time: 3.792 seconds
- Evaluation Time: 0.022 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 124127895556224.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.40%
- matrix_size_y: 1.56%
- p1: 3.57%
- p2: 1.05%
- p3: 34.67%
- p4: 26.76%
- p5: 3.59%
- p6: 15.50%
- p7: 5.94%
- p8: 3.95%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.729e-310
- Training Time: 0.011 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140618751742080.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.407e-310
- Training Time: 5.589 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135183116210304.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.62%
- matrix_size_y: 1.61%
- p1: 6.47%
- p2: 0.96%
- p3: 35.90%
- p4: 22.40%
- p5: 5.06%
- p6: 8.47%
- p7: 5.10%
- p8: 4.40%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.206e-310
- Training Time: 0.017 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127003499892864.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.483e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138209835027200.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.302e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123266387611776.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.820e-310
- Training Time: 5.439 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130303039310592.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.54%
- matrix_size_y: 1.37%
- p1: 7.88%
- p2: 0.82%
- p3: 36.27%
- p4: 21.75%
- p5: 5.46%
- p6: 7.23%
- p7: 4.24%
- p8: 4.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.078 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.064 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.822e-310
- Training Time: 27.464 seconds
- Evaluation Time: 0.121 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.28%
- matrix_size_y: 0.32%
- p1: 10.02%
- p2: 0.22%
- p3: 70.31%
- p4: 5.22%
- p5: 4.50%
- p6: 2.28%
- p7: 0.67%
- p8: 1.19%

---

### Bagging

#### Performance Metrics
- MSE: 4.916e-310
- Training Time: 27.440 seconds
- Evaluation Time: 0.225 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.34%
- p1: 9.77%
- p2: 0.26%
- p3: 70.16%
- p4: 5.28%
- p5: 4.47%
- p6: 2.39%
- p7: 0.59%
- p8: 1.28%

---

### Bagging

#### Performance Metrics
- MSE: 5.198e-310
- Training Time: 27.563 seconds
- Evaluation Time: 0.119 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.29%
- p1: 9.69%
- p2: 0.22%
- p3: 70.59%
- p4: 5.41%
- p5: 4.25%
- p6: 2.40%
- p7: 0.66%
- p8: 1.34%

---

### Bagging

#### Performance Metrics
- MSE: 5.266e-310
- Training Time: 8.904 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.76%
- matrix_size_y: 0.40%
- p1: 9.58%
- p2: 0.19%
- p3: 70.38%
- p4: 5.65%
- p5: 4.09%
- p6: 2.25%
- p7: 0.57%
- p8: 1.15%

---

### Bagging

#### Performance Metrics
- MSE: 4.865e-310
- Training Time: 8.798 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.91%
- matrix_size_y: 0.47%
- p1: 10.12%
- p2: 0.21%
- p3: 70.45%
- p4: 5.14%
- p5: 4.57%
- p6: 2.15%
- p7: 0.57%
- p8: 1.41%

---

### Bagging

#### Performance Metrics
- MSE: 4.756e-310
- Training Time: 8.917 seconds
- Evaluation Time: 0.134 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.37%
- p1: 9.96%
- p2: 0.22%
- p3: 70.66%
- p4: 5.30%
- p5: 4.33%
- p6: 2.47%
- p7: 0.50%
- p8: 1.04%

---

### Bagging

#### Performance Metrics
- MSE: 5.058e-310
- Training Time: 5.483 seconds
- Evaluation Time: 0.164 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.74%
- matrix_size_y: 0.40%
- p1: 9.96%
- p2: 0.22%
- p3: 70.27%
- p4: 5.32%
- p5: 4.22%
- p6: 2.16%
- p7: 0.62%
- p8: 1.08%

---

### Bagging

#### Performance Metrics
- MSE: 5.006e-310
- Training Time: 5.658 seconds
- Evaluation Time: 0.138 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.05%
- matrix_size_y: 0.36%
- p1: 10.08%
- p2: 0.24%
- p3: 70.09%
- p4: 5.29%
- p5: 4.81%
- p6: 2.22%
- p7: 0.57%
- p8: 1.29%

---

### Bagging

#### Performance Metrics
- MSE: 4.789e-310
- Training Time: 5.688 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.03%
- matrix_size_y: 0.34%
- p1: 9.93%
- p2: 0.22%
- p3: 70.13%
- p4: 5.55%
- p5: 4.50%
- p6: 2.41%
- p7: 0.53%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.173e-310
- Training Time: 5.323 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.49%
- matrix_size_y: 0.35%
- p1: 9.73%
- p2: 0.24%
- p3: 70.55%
- p4: 5.29%
- p5: 4.08%
- p6: 2.47%
- p7: 0.55%
- p8: 1.25%

---

### Bagging

#### Performance Metrics
- MSE: 4.701e-310
- Training Time: 5.485 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.28%
- matrix_size_y: 0.32%
- p1: 10.04%
- p2: 0.24%
- p3: 70.31%
- p4: 5.30%
- p5: 4.50%
- p6: 2.23%
- p7: 0.54%
- p8: 1.25%

---

### Bagging

#### Performance Metrics
- MSE: 4.853e-310
- Training Time: 5.368 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.60%
- matrix_size_y: 0.36%
- p1: 9.87%
- p2: 0.21%
- p3: 70.18%
- p4: 5.47%
- p5: 3.83%
- p6: 2.47%
- p7: 0.65%
- p8: 1.37%

---

### Boosting

#### Performance Metrics
- MSE: 5.149e-310
- Training Time: 3.932 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.267e-310
- Training Time: 3.897 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.027e-310
- Training Time: 3.916 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.814e-310
- Training Time: 2.934 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.123e-310
- Training Time: 2.944 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.210e-310
- Training Time: 2.901 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.843e-310
- Training Time: 2.285 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.210e-310
- Training Time: 2.307 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.011e-310
- Training Time: 2.352 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.653e-310
- Training Time: 2.359 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.124e-310
- Training Time: 2.397 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.330e-310
- Training Time: 2.359 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.160 seconds
- Evaluation Time: 0.053 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.167 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.170 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.172 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.159 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.153 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.162 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.155 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.159 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.425e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125237265894144.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.009e-310
- Training Time: 2.683 seconds
- Evaluation Time: 0.108 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126214347784320.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.95%
- matrix_size_y: 1.33%
- p1: 7.92%
- p2: 0.82%
- p3: 36.26%
- p4: 21.75%
- p5: 5.58%
- p6: 6.91%
- p7: 4.15%
- p8: 4.33%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.695e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135005657870464.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.299e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127257072832640.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.475e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 132526610205440.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.378e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123817160544384.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.638e-310
- Training Time: 5.438 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 139749280911488.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 11.04%
- matrix_size_y: 1.44%
- p1: 7.87%
- p2: 0.80%
- p3: 36.12%
- p4: 21.80%
- p5: 5.38%
- p6: 6.88%
- p7: 4.28%
- p8: 4.40%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.137 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.167e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135546290507904.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.353e-310
- Training Time: 2.507 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136725359693952.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.487e-310
- Training Time: 2.515 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129574700518144.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.715e-310
- Training Time: 0.028 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129417189724288.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.778e-310
- Training Time: 5.186 seconds
- Evaluation Time: 0.030 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126064535735040.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.70%
- matrix_size_y: 1.37%
- p1: 8.03%
- p2: 0.82%
- p3: 36.77%
- p4: 21.59%
- p5: 5.21%
- p6: 7.12%
- p7: 3.95%
- p8: 4.43%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.909e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133682849321088.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.132e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137039640989824.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.831e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135696324956288.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.328e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138548955433728.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.195e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126226121506944.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.873e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125620054855808.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.221e-310
- Training Time: 2.500 seconds
- Evaluation Time: 0.092 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125223714099328.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.393e-310
- Training Time: 2.507 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123144872921856.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.028e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133124167924480.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.849e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136013765233408.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.452e-310
- Training Time: 4.947 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136449420628096.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 11.01%
- matrix_size_y: 1.40%
- p1: 7.84%
- p2: 0.81%
- p3: 36.17%
- p4: 21.66%
- p5: 5.40%
- p6: 7.05%
- p7: 4.25%
- p8: 4.41%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.935e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 139939503083648.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.447e-310
- Training Time: 5.173 seconds
- Evaluation Time: 0.030 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130032380873472.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.92%
- matrix_size_y: 1.38%
- p1: 7.82%
- p2: 0.88%
- p3: 36.28%
- p4: 21.79%
- p5: 5.37%
- p6: 7.14%
- p7: 4.06%
- p8: 4.35%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.701e-310
- Training Time: 0.022 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137976045256832.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.856e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136834877165696.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.821e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129898905538688.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

