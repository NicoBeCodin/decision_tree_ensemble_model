# Decision Tree Models Comparison

## Performance Results

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.564e-04
- Training Time: 0.011 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 1.62%
- matrix_size_y: -0.14%
- p1: 15.37%
- p2: 0.10%
- p3: 96.70%
- p4: -14.70%
- p5: 2.87%
- p6: 5.95%
- p7: -8.23%
- p8: 0.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.564e-04
- Training Time: 0.035 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 1.62%
- matrix_size_y: -0.14%
- p1: 15.37%
- p2: 0.10%
- p3: 96.70%
- p4: -14.70%
- p5: 2.87%
- p6: 5.95%
- p7: -8.23%
- p8: 0.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.990e-04
- Training Time: 0.101 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.21%
- matrix_size_y: -0.32%
- p1: 15.72%
- p2: 0.00%
- p3: 107.23%
- p4: -18.95%
- p5: 0.23%
- p6: 6.58%
- p7: -10.70%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.721e-04
- Training Time: 0.941 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -16.61%
- matrix_size_y: 0.00%
- p1: 4.89%
- p2: 0.00%
- p3: 82.25%
- p4: 8.75%
- p5: 1.54%
- p6: 34.65%
- p7: -15.48%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.721 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.362e-04
- Training Time: 40.764 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -7.87%
- matrix_size_y: 1.08%
- p1: 7.73%
- p2: 0.73%
- p3: 54.98%
- p4: 21.71%
- p5: 3.32%
- p6: 25.79%
- p7: -9.74%
- p8: 2.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.362e-04
- Training Time: 0.207 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -7.87%
- matrix_size_y: 1.08%
- p1: 7.73%
- p2: 0.73%
- p3: 54.98%
- p4: 21.71%
- p5: 3.32%
- p6: 25.79%
- p7: -9.74%
- p8: 2.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.326 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.426e-04
- Training Time: 0.325 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -6.23%
- matrix_size_y: 1.49%
- p1: 9.00%
- p2: 1.56%
- p3: 50.32%
- p4: 20.38%
- p5: 4.23%
- p6: 23.98%
- p7: -7.66%
- p8: 2.92%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 1.942 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- max_depth: 5.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 10.000

#### Feature Importance
- matrix_size_x: -6.47%
- matrix_size_y: 0.00%
- p1: 9.27%
- p2: 0.22%
- p3: 68.59%
- p4: 5.33%
- p5: 3.12%
- p6: 38.04%
- p7: -17.85%
- p8: -0.24%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 30.238 seconds
- Evaluation Time: 0.061 seconds

#### Model Parameters
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 30.000

#### Feature Importance
- matrix_size_x: 3.39%
- matrix_size_y: 0.27%
- p1: 9.81%
- p2: 0.50%
- p3: 45.30%
- p4: 28.75%
- p5: 5.63%
- p6: 5.55%
- p7: -3.18%
- p8: 3.99%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 28.059 seconds
- Evaluation Time: 0.033 seconds

#### Model Parameters
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 30.000

#### Feature Importance
- matrix_size_x: 2.42%
- matrix_size_y: 0.31%
- p1: 8.41%
- p2: 0.45%
- p3: 45.33%
- p4: 30.31%
- p5: 5.79%
- p6: 5.40%
- p7: -2.70%
- p8: 4.28%

---

### Bagging

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 12443312354.000 seconds
- Evaluation Time: 69183979.000 seconds

#### Model Parameters
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000

#### Feature Importance
- matrix_size_x: 1.04%
- matrix_size_y: 1.82%
- p1: 12.99%
- p2: 1.52%
- p3: 47.80%
- p4: 15.53%
- p5: 4.99%
- p6: 19.75%
- p7: -9.14%
- p8: 3.70%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.176 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 100.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.939 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 30.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: -nan%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 9.881e-324
- Training Time: 4205149168.000 seconds
- Evaluation Time: 62777107.000 seconds

#### Model Parameters
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.562 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000

#### Feature Importance
- matrix_size_x: -4.82%
- matrix_size_y: 2.11%
- p1: 7.46%
- p2: 1.12%
- p3: 50.08%
- p4: 20.20%
- p5: 4.48%
- p6: 23.98%
- p7: -7.58%
- p8: 2.98%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.027e-03
- Training Time: 0.246 seconds
- Evaluation Time: 0.002 seconds
### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.289e-310
- Training Time: 1.973 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### Boosting

#### Performance Metrics
- MSE: 5.485e-310
- Training Time: 13.069 seconds
- Evaluation Time: 0.091 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_omp: 0.000
- use_split_histogram: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Bagging

#### Performance Metrics
- MSE: 4.943e-310
- Training Time: 20.258 seconds
- Evaluation Time: 0.052 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 60.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 20.000
- num_threads: 1.000
- use_omp: 0.000
- use_split_histogram: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.56%
- matrix_size_y: 0.61%
- p1: 3.31%
- p2: 0.56%
- p3: 76.94%
- p4: 6.62%
- p5: 1.61%
- p6: 6.51%
- p7: 1.07%
- p8: 1.20%

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 5.005e-310
- Training Time: 1.420 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
Feature importance not available for this model.

---

### AdvancedGBDT (Frequency)

#### Performance Metrics
- MSE: 8.413e-04
- Training Time: 1.341 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.500
- learning_rate: 0.010
- max_depth: 50.000
- min_data_in_leaf: 1.000
- n_estimators: 200.000
- num_bins: 1024.000
- num_threads: 8.000
- skip_drop_rate: 0.300
- use_dart: 1.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.717e-310
- Training Time: 17.176 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_omp: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.70%
- matrix_size_y: 1.19%
- p1: 7.98%
- p2: 1.06%
- p3: 36.02%
- p4: 20.49%
- p5: 4.67%
- p6: 18.11%
- p7: 2.67%
- p8: 3.10%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.158 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.094e-310
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- dropout_rate: 0.150
- learning_rate: 0.050
- max_depth: 15.000
- min_data_leaf: 5.000
- n_estimators: 100.000
- num_bins: 256.000
- num_threads: 8.000
- skip_drop_rate: 0.100
- use_dart: 1.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.255e-310
- Training Time: 0.065 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.693e-310
- Training Time: 0.068 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.217e-310
- Training Time: 0.065 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.165 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.215e-310
- Training Time: 4.905 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.95%
- matrix_size_y: 0.61%
- p1: 3.08%
- p2: 0.09%
- p3: 39.25%
- p4: 27.55%
- p5: 2.30%
- p6: 16.01%
- p7: 5.62%
- p8: 2.52%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.448 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- colsample_bytree: 1.000
- learning_rate: 0.100
- max_depth: -1.000
- n_estimators: 100.000
- num_leaves: 31.000
- subsample: 1.000

#### Feature Importance
- F0: 220.57%
- F1: 10.74%
- F2: 1831.37%
- F3: 1371.74%
- F4: 173.82%
- F5: 865.24%
- F6: 487.48%
- F7: 185.44%
- F8: 278.41%
- F9: 68.58%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.959e-310
- Training Time: 7.999 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.010
- max_depth: 3.000
- min_data_leaf: 30.000
- n_estimators: 200.000
- num_bins: 500.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.81%
- matrix_size_y: 0.02%
- p1: 1.29%
- p2: 0.00%
- p3: 50.83%
- p4: 31.58%
- p5: 0.16%
- p6: 13.82%
- p7: 1.24%
- p8: 0.24%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.371e-310
- Training Time: 4.972 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 100.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.95%
- matrix_size_y: 0.61%
- p1: 3.08%
- p2: 0.09%
- p3: 39.25%
- p4: 27.55%
- p5: 2.30%
- p6: 16.01%
- p7: 5.62%
- p8: 2.52%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.415e-310
- Training Time: 2.390 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 50.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.85%
- matrix_size_y: 0.55%
- p1: 3.12%
- p2: 0.07%
- p3: 41.15%
- p4: 28.16%
- p5: 1.82%
- p6: 15.33%
- p7: 4.74%
- p8: 2.20%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.009e-310
- Training Time: 2.377 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 50.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 2.85%
- matrix_size_y: 0.55%
- p1: 3.12%
- p2: 0.07%
- p3: 41.15%
- p4: 28.16%
- p5: 1.82%
- p6: 15.33%
- p7: 4.74%
- p8: 2.20%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.175e-310
- Training Time: 7.846 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.731e-310
- Training Time: 8.179 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.503e-310
- Training Time: 8.149 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.639e-310
- Training Time: 0.120 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.964e-310
- Training Time: 6.038 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.136e-310
- Training Time: 1.508 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 1.52%
- matrix_size_y: 3.51%
- p1: 6.37%
- p2: 0.68%
- p3: 26.19%
- p4: 11.36%
- p5: 12.57%
- p6: 20.37%
- p7: 13.64%
- p8: 3.78%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.216e-310
- Training Time: 10.212 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.03%
- matrix_size_y: 0.06%
- p1: 99.40%
- p2: 0.02%
- p3: 0.08%
- p4: 0.11%
- p5: 0.11%
- p6: 0.08%
- p7: 0.03%
- p8: 0.08%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.485e-310
- Training Time: 8.541 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.488e-310
- Training Time: 3.300 seconds
- Evaluation Time: 0.012 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.03%
- matrix_size_y: 0.06%
- p1: 99.40%
- p2: 0.02%
- p3: 0.08%
- p4: 0.11%
- p5: 0.11%
- p6: 0.08%
- p7: 0.03%
- p8: 0.08%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.251e-310
- Training Time: 7.945 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.139e-310
- Training Time: 6.006 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.827e-310
- Training Time: 5.743 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 8.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.21%
- matrix_size_y: 0.73%
- p1: 2.92%
- p2: 0.14%
- p3: 38.02%
- p4: 26.98%
- p5: 2.64%
- p6: 16.18%
- p7: 6.44%
- p8: 2.76%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.065 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.324e-310
- Training Time: 27.572 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.39%
- p1: 9.80%
- p2: 0.20%
- p3: 70.11%
- p4: 5.46%
- p5: 4.48%
- p6: 2.22%
- p7: 0.65%
- p8: 1.28%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.137 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.137 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.104 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.649e-310
- Training Time: 27.683 seconds
- Evaluation Time: 0.117 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.57%
- matrix_size_y: 0.33%
- p1: 9.85%
- p2: 0.22%
- p3: 70.51%
- p4: 5.42%
- p5: 4.05%
- p6: 2.25%
- p7: 0.54%
- p8: 1.26%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.079 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.076 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.069 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.720e-310
- Training Time: 27.441 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.04%
- matrix_size_y: 0.40%
- p1: 9.78%
- p2: 0.23%
- p3: 70.39%
- p4: 5.18%
- p5: 4.56%
- p6: 2.45%
- p7: 0.51%
- p8: 1.46%

---

### Bagging

#### Performance Metrics
- MSE: 5.154e-310
- Training Time: 27.568 seconds
- Evaluation Time: 0.125 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.43%
- matrix_size_y: 0.32%
- p1: 9.81%
- p2: 0.24%
- p3: 70.42%
- p4: 5.60%
- p5: 4.19%
- p6: 2.19%
- p7: 0.54%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.957e-310
- Training Time: 27.625 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.57%
- matrix_size_y: 0.28%
- p1: 9.92%
- p2: 0.26%
- p3: 70.32%
- p4: 5.20%
- p5: 4.19%
- p6: 2.40%
- p7: 0.56%
- p8: 1.31%

---

### Bagging

#### Performance Metrics
- MSE: 5.163e-310
- Training Time: 8.740 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.23%
- matrix_size_y: 0.36%
- p1: 10.01%
- p2: 0.28%
- p3: 70.03%
- p4: 5.58%
- p5: 4.32%
- p6: 2.39%
- p7: 0.62%
- p8: 1.19%

---

### Bagging

#### Performance Metrics
- MSE: 5.038e-310
- Training Time: 8.797 seconds
- Evaluation Time: 0.111 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.24%
- matrix_size_y: 0.34%
- p1: 9.56%
- p2: 0.21%
- p3: 70.81%
- p4: 5.41%
- p5: 4.27%
- p6: 2.23%
- p7: 0.59%
- p8: 1.33%

---

### Bagging

#### Performance Metrics
- MSE: 5.055e-310
- Training Time: 8.828 seconds
- Evaluation Time: 0.118 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.63%
- matrix_size_y: 0.38%
- p1: 9.82%
- p2: 0.26%
- p3: 70.49%
- p4: 5.32%
- p5: 3.99%
- p6: 2.36%
- p7: 0.54%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 5.231e-310
- Training Time: 5.505 seconds
- Evaluation Time: 0.155 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.51%
- matrix_size_y: 0.42%
- p1: 9.76%
- p2: 0.25%
- p3: 70.37%
- p4: 5.29%
- p5: 4.20%
- p6: 2.53%
- p7: 0.57%
- p8: 1.11%

---

### Bagging

#### Performance Metrics
- MSE: 5.284e-310
- Training Time: 5.081 seconds
- Evaluation Time: 0.136 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.26%
- matrix_size_y: 0.35%
- p1: 10.03%
- p2: 0.22%
- p3: 70.43%
- p4: 5.40%
- p5: 3.98%
- p6: 2.32%
- p7: 0.67%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.126e-310
- Training Time: 5.837 seconds
- Evaluation Time: 0.182 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.35%
- p1: 9.72%
- p2: 0.23%
- p3: 70.35%
- p4: 5.46%
- p5: 4.20%
- p6: 2.36%
- p7: 0.56%
- p8: 1.34%

---

### Bagging

#### Performance Metrics
- MSE: 4.894e-310
- Training Time: 5.603 seconds
- Evaluation Time: 0.212 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.46%
- matrix_size_y: 0.37%
- p1: 10.01%
- p2: 0.21%
- p3: 69.89%
- p4: 5.31%
- p5: 4.33%
- p6: 2.57%
- p7: 0.60%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 5.487e-310
- Training Time: 6.396 seconds
- Evaluation Time: 0.197 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.32%
- p1: 9.80%
- p2: 0.24%
- p3: 70.44%
- p4: 5.13%
- p5: 4.58%
- p6: 2.43%
- p7: 0.64%
- p8: 1.28%

---

### Bagging

#### Performance Metrics
- MSE: 4.980e-310
- Training Time: 5.561 seconds
- Evaluation Time: 0.157 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.38%
- p1: 9.82%
- p2: 0.22%
- p3: 70.34%
- p4: 5.37%
- p5: 4.33%
- p6: 2.42%
- p7: 0.66%
- p8: 1.32%

---

### Boosting

#### Performance Metrics
- MSE: 4.828e-310
- Training Time: 3.863 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.136e-310
- Training Time: 3.867 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.099e-310
- Training Time: 3.868 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.390e-310
- Training Time: 2.908 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.403e-310
- Training Time: 2.932 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.030e-310
- Training Time: 2.916 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.868e-310
- Training Time: 2.306 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.033e-310
- Training Time: 2.279 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.858e-310
- Training Time: 2.291 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.146e-310
- Training Time: 2.390 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.342e-310
- Training Time: 2.325 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.053e-310
- Training Time: 2.337 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.173 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.162 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.173 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.185 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.137 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.164 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.154 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.139 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.167 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.155 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.178 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.417e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 132529881563264.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.734e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 128016948595456.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.941e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 131960162898048.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.079e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129120205738112.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.055e-310
- Training Time: 0.020 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140038971001600.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.707e-310
- Training Time: 0.023 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130757104861312.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.816e-310
- Training Time: 5.221 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130875970751232.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.77%
- matrix_size_y: 1.36%
- p1: 7.80%
- p2: 0.80%
- p3: 36.33%
- p4: 21.85%
- p5: 5.40%
- p6: 7.18%
- p7: 4.11%
- p8: 4.39%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.158e-310
- Training Time: 0.029 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129107692841728.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.030 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.031 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.052 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.111e-310
- Training Time: 4.138 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.44%
- matrix_size_y: 0.38%
- p1: 2.90%
- p2: 0.29%
- p3: 77.28%
- p4: 5.27%
- p5: 1.03%
- p6: 9.60%
- p7: 0.61%
- p8: 1.21%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.426e-310
- Training Time: 5.454 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126192787798784.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.90%
- matrix_size_y: 1.45%
- p1: 7.90%
- p2: 0.81%
- p3: 36.15%
- p4: 21.60%
- p5: 5.45%
- p6: 7.04%
- p7: 4.27%
- p8: 4.44%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.786e-310
- Training Time: 5.227 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 128083065507968.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.82%
- matrix_size_y: 1.36%
- p1: 7.87%
- p2: 0.81%
- p3: 36.22%
- p4: 21.81%
- p5: 5.51%
- p6: 6.99%
- p7: 4.13%
- p8: 4.47%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.063e-310
- Training Time: 0.022 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133414955344000.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.063 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.058e-310
- Training Time: 27.557 seconds
- Evaluation Time: 0.113 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.52%
- matrix_size_y: 0.30%
- p1: 9.70%
- p2: 0.20%
- p3: 70.61%
- p4: 5.55%
- p5: 4.19%
- p6: 2.09%
- p7: 0.59%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.727e-310
- Training Time: 27.274 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.76%
- matrix_size_y: 0.34%
- p1: 9.90%
- p2: 0.25%
- p3: 70.38%
- p4: 5.31%
- p5: 3.82%
- p6: 2.39%
- p7: 0.64%
- p8: 1.22%

---

### Bagging

#### Performance Metrics
- MSE: 5.439e-310
- Training Time: 27.349 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.37%
- matrix_size_y: 0.37%
- p1: 9.78%
- p2: 0.23%
- p3: 70.20%
- p4: 5.39%
- p5: 4.56%
- p6: 2.37%
- p7: 0.50%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 4.999e-310
- Training Time: 8.703 seconds
- Evaluation Time: 0.111 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.04%
- matrix_size_y: 0.31%
- p1: 9.59%
- p2: 0.23%
- p3: 70.19%
- p4: 5.41%
- p5: 4.64%
- p6: 2.51%
- p7: 0.58%
- p8: 1.49%

---

### Bagging

#### Performance Metrics
- MSE: 5.466e-310
- Training Time: 8.744 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.50%
- matrix_size_y: 0.32%
- p1: 10.11%
- p2: 0.27%
- p3: 70.26%
- p4: 5.20%
- p5: 4.27%
- p6: 2.27%
- p7: 0.67%
- p8: 1.12%

---

### Bagging

#### Performance Metrics
- MSE: 4.748e-310
- Training Time: 8.835 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.33%
- p1: 9.88%
- p2: 0.25%
- p3: 69.99%
- p4: 5.40%
- p5: 4.34%
- p6: 2.69%
- p7: 0.46%
- p8: 1.21%

---

### Bagging

#### Performance Metrics
- MSE: 4.826e-310
- Training Time: 5.001 seconds
- Evaluation Time: 0.143 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.23%
- matrix_size_y: 0.36%
- p1: 9.81%
- p2: 0.23%
- p3: 70.52%
- p4: 5.34%
- p5: 4.32%
- p6: 2.22%
- p7: 0.66%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.368e-310
- Training Time: 4.908 seconds
- Evaluation Time: 0.134 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.39%
- matrix_size_y: 0.40%
- p1: 9.92%
- p2: 0.25%
- p3: 70.10%
- p4: 5.36%
- p5: 4.09%
- p6: 2.76%
- p7: 0.55%
- p8: 1.19%

---

### Bagging

#### Performance Metrics
- MSE: 4.795e-310
- Training Time: 4.887 seconds
- Evaluation Time: 0.136 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.54%
- matrix_size_y: 0.36%
- p1: 10.00%
- p2: 0.29%
- p3: 70.38%
- p4: 5.19%
- p5: 4.02%
- p6: 2.35%
- p7: 0.60%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 4.694e-310
- Training Time: 5.210 seconds
- Evaluation Time: 0.164 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.47%
- matrix_size_y: 0.40%
- p1: 9.60%
- p2: 0.25%
- p3: 70.22%
- p4: 5.21%
- p5: 4.67%
- p6: 2.23%
- p7: 0.60%
- p8: 1.36%

---

### Bagging

#### Performance Metrics
- MSE: 5.422e-310
- Training Time: 5.055 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.39%
- p1: 9.78%
- p2: 0.24%
- p3: 70.32%
- p4: 5.27%
- p5: 4.25%
- p6: 2.46%
- p7: 0.59%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 4.657e-310
- Training Time: 5.024 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.26%
- matrix_size_y: 0.31%
- p1: 9.80%
- p2: 0.21%
- p3: 70.51%
- p4: 5.52%
- p5: 4.25%
- p6: 2.26%
- p7: 0.63%
- p8: 1.25%

---

### Boosting

#### Performance Metrics
- MSE: 4.807e-310
- Training Time: 3.867 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.186e-310
- Training Time: 3.855 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.798e-310
- Training Time: 3.867 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.470e-310
- Training Time: 2.891 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.083e-310
- Training Time: 2.891 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.397e-310
- Training Time: 2.897 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.794e-310
- Training Time: 2.291 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.490e-310
- Training Time: 2.258 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.934e-310
- Training Time: 2.284 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.269e-310
- Training Time: 2.320 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.846e-310
- Training Time: 2.301 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.680e-310
- Training Time: 2.344 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.171 seconds
- Evaluation Time: 0.027 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.175 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.174 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.157 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.160 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.145 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.204 seconds
- Evaluation Time: 0.012 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.187 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.191 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.221e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125860807904000.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.359e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127059020688128.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.940e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140356652175488.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.390e-310
- Training Time: 0.019 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135992551766784.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.965e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140192399354624.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.473e-310
- Training Time: 0.023 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123336012886144.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.724e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136895459691264.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.922e-310
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137405860350720.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.045e-310
- Training Time: 0.071 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 124280496917248.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.639e-310
- Training Time: 0.782 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138367637764864.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.903e-04
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.94%
- matrix_size_y: 0.24%
- p1: 2.19%
- p2: 0.75%
- p3: 74.49%
- p4: 5.90%
- p5: 1.17%
- p6: 11.89%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.028 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.045 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.046 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.029e-310
- Training Time: 4.212 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.29%
- matrix_size_y: 0.52%
- p1: 3.61%
- p2: 0.42%
- p3: 75.22%
- p4: 4.79%
- p5: 0.76%
- p6: 11.64%
- p7: 0.81%
- p8: 0.95%

---

### Bagging

#### Performance Metrics
- MSE: 4.664e-310
- Training Time: 4.190 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.24%
- matrix_size_y: 0.26%
- p1: 3.47%
- p2: 0.58%
- p3: 78.26%
- p4: 4.48%
- p5: 1.36%
- p6: 8.57%
- p7: 0.72%
- p8: 1.04%

---

### Bagging

#### Performance Metrics
- MSE: 5.415e-310
- Training Time: 4.192 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.27%
- matrix_size_y: 0.30%
- p1: 3.88%
- p2: 0.56%
- p3: 75.78%
- p4: 5.60%
- p5: 0.83%
- p6: 10.39%
- p7: 0.50%
- p8: 0.89%

---

### Bagging

#### Performance Metrics
- MSE: 4.689e-310
- Training Time: 2.902 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.71%
- matrix_size_y: 0.39%
- p1: 3.71%
- p2: 0.29%
- p3: 77.93%
- p4: 6.33%
- p5: 1.35%
- p6: 5.57%
- p7: 1.31%
- p8: 1.41%

---

### Bagging

#### Performance Metrics
- MSE: 4.809e-310
- Training Time: 2.985 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.67%
- matrix_size_y: 0.42%
- p1: 4.18%
- p2: 0.43%
- p3: 76.66%
- p4: 5.70%
- p5: 1.51%
- p6: 7.31%
- p7: 0.79%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.446e-310
- Training Time: 3.055 seconds
- Evaluation Time: 0.050 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.52%
- matrix_size_y: 0.40%
- p1: 4.38%
- p2: 0.42%
- p3: 78.00%
- p4: 6.49%
- p5: 1.34%
- p6: 5.54%
- p7: 0.83%
- p8: 1.07%

---

### Bagging

#### Performance Metrics
- MSE: 5.286e-310
- Training Time: 3.394 seconds
- Evaluation Time: 0.104 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.70%
- matrix_size_y: 0.38%
- p1: 10.26%
- p2: 0.28%
- p3: 72.34%
- p4: 5.05%
- p5: 3.03%
- p6: 2.59%
- p7: 0.94%
- p8: 1.44%

---

### Bagging

#### Performance Metrics
- MSE: 4.827e-310
- Training Time: 3.544 seconds
- Evaluation Time: 0.117 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.73%
- matrix_size_y: 0.46%
- p1: 10.41%
- p2: 0.28%
- p3: 72.84%
- p4: 4.71%
- p5: 2.86%
- p6: 2.62%
- p7: 0.79%
- p8: 1.29%

---

### Bagging

#### Performance Metrics
- MSE: 5.161e-310
- Training Time: 3.417 seconds
- Evaluation Time: 0.094 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.75%
- matrix_size_y: 0.45%
- p1: 9.76%
- p2: 0.26%
- p3: 72.95%
- p4: 5.19%
- p5: 2.93%
- p6: 2.46%
- p7: 0.85%
- p8: 1.39%

---

### Bagging

#### Performance Metrics
- MSE: 5.267e-310
- Training Time: 5.036 seconds
- Evaluation Time: 0.151 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.44%
- matrix_size_y: 0.37%
- p1: 9.64%
- p2: 0.26%
- p3: 70.47%
- p4: 5.43%
- p5: 4.03%
- p6: 2.44%
- p7: 0.58%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 5.220e-310
- Training Time: 4.864 seconds
- Evaluation Time: 0.152 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.35%
- matrix_size_y: 0.35%
- p1: 9.65%
- p2: 0.23%
- p3: 70.37%
- p4: 5.62%
- p5: 4.35%
- p6: 2.32%
- p7: 0.52%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 4.734e-310
- Training Time: 4.954 seconds
- Evaluation Time: 0.153 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.24%
- matrix_size_y: 0.32%
- p1: 9.94%
- p2: 0.25%
- p3: 69.95%
- p4: 5.20%
- p5: 4.74%
- p6: 2.49%
- p7: 0.52%
- p8: 1.34%

---

### Boosting

#### Performance Metrics
- MSE: 5.249e-310
- Training Time: 0.516 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.418e-310
- Training Time: 0.515 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.918e-310
- Training Time: 0.515 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.331e-310
- Training Time: 0.827 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.158e-310
- Training Time: 0.831 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.162e-310
- Training Time: 0.824 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.368e-310
- Training Time: 1.539 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 4.663e-310
- Training Time: 1.559 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.339e-310
- Training Time: 1.521 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.123e-310
- Training Time: 2.377 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.107e-310
- Training Time: 2.351 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.684e-310
- Training Time: 2.351 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.053 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.054 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.057 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.094 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.093 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.093 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.128 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.125 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.136 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.159 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.185 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.160 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.848e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125856716360448.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.711e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138530554581120.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.440e-310
- Training Time: 3.792 seconds
- Evaluation Time: 0.022 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 124127895556224.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.40%
- matrix_size_y: 1.56%
- p1: 3.57%
- p2: 1.05%
- p3: 34.67%
- p4: 26.76%
- p5: 3.59%
- p6: 15.50%
- p7: 5.94%
- p8: 3.95%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.729e-310
- Training Time: 0.011 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140618751742080.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.407e-310
- Training Time: 5.589 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135183116210304.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.62%
- matrix_size_y: 1.61%
- p1: 6.47%
- p2: 0.96%
- p3: 35.90%
- p4: 22.40%
- p5: 5.06%
- p6: 8.47%
- p7: 5.10%
- p8: 4.40%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.206e-310
- Training Time: 0.017 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127003499892864.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.483e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138209835027200.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.302e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123266387611776.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.820e-310
- Training Time: 5.439 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130303039310592.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.54%
- matrix_size_y: 1.37%
- p1: 7.88%
- p2: 0.82%
- p3: 36.27%
- p4: 21.75%
- p5: 5.46%
- p6: 7.23%
- p7: 4.24%
- p8: 4.45%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.078 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.064 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.822e-310
- Training Time: 27.464 seconds
- Evaluation Time: 0.121 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.28%
- matrix_size_y: 0.32%
- p1: 10.02%
- p2: 0.22%
- p3: 70.31%
- p4: 5.22%
- p5: 4.50%
- p6: 2.28%
- p7: 0.67%
- p8: 1.19%

---

### Bagging

#### Performance Metrics
- MSE: 4.916e-310
- Training Time: 27.440 seconds
- Evaluation Time: 0.225 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.34%
- p1: 9.77%
- p2: 0.26%
- p3: 70.16%
- p4: 5.28%
- p5: 4.47%
- p6: 2.39%
- p7: 0.59%
- p8: 1.28%

---

### Bagging

#### Performance Metrics
- MSE: 5.198e-310
- Training Time: 27.563 seconds
- Evaluation Time: 0.119 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.29%
- p1: 9.69%
- p2: 0.22%
- p3: 70.59%
- p4: 5.41%
- p5: 4.25%
- p6: 2.40%
- p7: 0.66%
- p8: 1.34%

---

### Bagging

#### Performance Metrics
- MSE: 5.266e-310
- Training Time: 8.904 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.76%
- matrix_size_y: 0.40%
- p1: 9.58%
- p2: 0.19%
- p3: 70.38%
- p4: 5.65%
- p5: 4.09%
- p6: 2.25%
- p7: 0.57%
- p8: 1.15%

---

### Bagging

#### Performance Metrics
- MSE: 4.865e-310
- Training Time: 8.798 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.91%
- matrix_size_y: 0.47%
- p1: 10.12%
- p2: 0.21%
- p3: 70.45%
- p4: 5.14%
- p5: 4.57%
- p6: 2.15%
- p7: 0.57%
- p8: 1.41%

---

### Bagging

#### Performance Metrics
- MSE: 4.756e-310
- Training Time: 8.917 seconds
- Evaluation Time: 0.134 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.15%
- matrix_size_y: 0.37%
- p1: 9.96%
- p2: 0.22%
- p3: 70.66%
- p4: 5.30%
- p5: 4.33%
- p6: 2.47%
- p7: 0.50%
- p8: 1.04%

---

### Bagging

#### Performance Metrics
- MSE: 5.058e-310
- Training Time: 5.483 seconds
- Evaluation Time: 0.164 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.74%
- matrix_size_y: 0.40%
- p1: 9.96%
- p2: 0.22%
- p3: 70.27%
- p4: 5.32%
- p5: 4.22%
- p6: 2.16%
- p7: 0.62%
- p8: 1.08%

---

### Bagging

#### Performance Metrics
- MSE: 5.006e-310
- Training Time: 5.658 seconds
- Evaluation Time: 0.138 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.05%
- matrix_size_y: 0.36%
- p1: 10.08%
- p2: 0.24%
- p3: 70.09%
- p4: 5.29%
- p5: 4.81%
- p6: 2.22%
- p7: 0.57%
- p8: 1.29%

---

### Bagging

#### Performance Metrics
- MSE: 4.789e-310
- Training Time: 5.688 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.03%
- matrix_size_y: 0.34%
- p1: 9.93%
- p2: 0.22%
- p3: 70.13%
- p4: 5.55%
- p5: 4.50%
- p6: 2.41%
- p7: 0.53%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.173e-310
- Training Time: 5.323 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.49%
- matrix_size_y: 0.35%
- p1: 9.73%
- p2: 0.24%
- p3: 70.55%
- p4: 5.29%
- p5: 4.08%
- p6: 2.47%
- p7: 0.55%
- p8: 1.25%

---

### Bagging

#### Performance Metrics
- MSE: 4.701e-310
- Training Time: 5.485 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.28%
- matrix_size_y: 0.32%
- p1: 10.04%
- p2: 0.24%
- p3: 70.31%
- p4: 5.30%
- p5: 4.50%
- p6: 2.23%
- p7: 0.54%
- p8: 1.25%

---

### Bagging

#### Performance Metrics
- MSE: 4.853e-310
- Training Time: 5.368 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.60%
- matrix_size_y: 0.36%
- p1: 9.87%
- p2: 0.21%
- p3: 70.18%
- p4: 5.47%
- p5: 3.83%
- p6: 2.47%
- p7: 0.65%
- p8: 1.37%

---

### Boosting

#### Performance Metrics
- MSE: 5.149e-310
- Training Time: 3.932 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.267e-310
- Training Time: 3.897 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.027e-310
- Training Time: 3.916 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.814e-310
- Training Time: 2.934 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.123e-310
- Training Time: 2.944 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.210e-310
- Training Time: 2.901 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.843e-310
- Training Time: 2.285 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.210e-310
- Training Time: 2.307 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.011e-310
- Training Time: 2.352 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.653e-310
- Training Time: 2.359 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.124e-310
- Training Time: 2.397 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.330e-310
- Training Time: 2.359 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.160 seconds
- Evaluation Time: 0.053 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.167 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.170 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.172 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.159 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.153 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.161 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.162 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.155 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 0.000e+00
- Training Time: 0.159 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.425e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125237265894144.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.009e-310
- Training Time: 2.683 seconds
- Evaluation Time: 0.108 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126214347784320.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.95%
- matrix_size_y: 1.33%
- p1: 7.92%
- p2: 0.82%
- p3: 36.26%
- p4: 21.75%
- p5: 5.58%
- p6: 6.91%
- p7: 4.15%
- p8: 4.33%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.695e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135005657870464.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.299e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127257072832640.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.475e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 132526610205440.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.378e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123817160544384.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.638e-310
- Training Time: 5.438 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 139749280911488.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 11.04%
- matrix_size_y: 1.44%
- p1: 7.87%
- p2: 0.80%
- p3: 36.12%
- p4: 21.80%
- p5: 5.38%
- p6: 6.88%
- p7: 4.28%
- p8: 4.40%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.137 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.135 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.167e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135546290507904.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.353e-310
- Training Time: 2.507 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136725359693952.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.487e-310
- Training Time: 2.515 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129574700518144.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.715e-310
- Training Time: 0.028 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129417189724288.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.778e-310
- Training Time: 5.186 seconds
- Evaluation Time: 0.030 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126064535735040.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.70%
- matrix_size_y: 1.37%
- p1: 8.03%
- p2: 0.82%
- p3: 36.77%
- p4: 21.59%
- p5: 5.21%
- p6: 7.12%
- p7: 3.95%
- p8: 4.43%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.909e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133682849321088.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.132e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137039640989824.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.831e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135696324956288.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.328e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 138548955433728.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.195e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126226121506944.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.873e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125620054855808.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.221e-310
- Training Time: 2.500 seconds
- Evaluation Time: 0.092 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125223714099328.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.393e-310
- Training Time: 2.507 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123144872921856.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.98%
- matrix_size_y: 1.21%
- p1: 7.51%
- p2: 0.88%
- p3: 37.40%
- p4: 21.67%
- p5: 5.27%
- p6: 7.65%
- p7: 4.31%
- p8: 4.11%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.028e-310
- Training Time: 0.026 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133124167924480.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.849e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136013765233408.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.452e-310
- Training Time: 4.947 seconds
- Evaluation Time: 0.028 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136449420628096.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 11.01%
- matrix_size_y: 1.40%
- p1: 7.84%
- p2: 0.81%
- p3: 36.17%
- p4: 21.66%
- p5: 5.40%
- p6: 7.05%
- p7: 4.25%
- p8: 4.41%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.935e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 139939503083648.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.447e-310
- Training Time: 5.173 seconds
- Evaluation Time: 0.030 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130032380873472.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.92%
- matrix_size_y: 1.38%
- p1: 7.82%
- p2: 0.88%
- p3: 36.28%
- p4: 21.79%
- p5: 5.37%
- p6: 7.14%
- p7: 4.06%
- p8: 4.35%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.701e-310
- Training Time: 0.022 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137976045256832.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.856e-310
- Training Time: 0.025 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136834877165696.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.821e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129898905538688.000
- n_estimators: 200.000
- num_bins: 128.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.940e-310
- Training Time: 26.577 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.47%
- matrix_size_y: 1.38%
- p1: 7.04%
- p2: 0.71%
- p3: 23.83%
- p4: 15.66%
- p5: 25.71%
- p6: 9.80%
- p7: 2.06%
- p8: 6.34%

---

### Boosting

#### Performance Metrics
- MSE: 4.972e-310
- Training Time: 4.642 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_omp: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 15.19%
- matrix_size_y: 2.00%
- p1: 25.29%
- p2: 0.85%
- p3: 15.97%
- p4: 14.68%
- p5: 13.08%
- p6: 6.70%
- p7: 2.17%
- p8: 4.08%

---

### Bagging

#### Performance Metrics
- MSE: 5.419e-310
- Training Time: 13.040 seconds
- Evaluation Time: 0.191 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.18%
- matrix_size_y: 0.53%
- p1: 5.93%
- p2: 0.51%
- p3: 23.41%
- p4: 19.16%
- p5: 30.72%
- p6: 7.35%
- p7: 0.72%
- p8: 3.50%

---

### Bagging

#### Performance Metrics
- MSE: 5.231e-310
- Training Time: 4.699 seconds
- Evaluation Time: 0.152 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.37%
- p1: 9.90%
- p2: 0.23%
- p3: 70.24%
- p4: 5.19%
- p5: 4.38%
- p6: 2.37%
- p7: 0.68%
- p8: 1.21%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.821e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.65%
- matrix_size_y: 0.64%
- p1: 10.70%
- p2: 0.08%
- p3: 70.67%
- p4: 4.88%
- p5: 4.48%
- p6: 2.12%
- p7: 0.60%
- p8: 1.19%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.864e-05
- Training Time: 0.244 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.71%
- p2: 0.09%
- p3: 70.68%
- p4: 4.87%
- p5: 4.48%
- p6: 2.13%
- p7: 0.60%
- p8: 1.17%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.847e-05
- Training Time: 0.229 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.71%
- p2: 0.09%
- p3: 70.69%
- p4: 4.87%
- p5: 4.48%
- p6: 2.12%
- p7: 0.59%
- p8: 1.18%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.065 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.956e-310
- Training Time: 24.060 seconds
- Evaluation Time: 0.118 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.43%
- p1: 9.94%
- p2: 0.26%
- p3: 70.17%
- p4: 5.32%
- p5: 4.46%
- p6: 2.15%
- p7: 0.57%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 5.411e-310
- Training Time: 23.748 seconds
- Evaluation Time: 0.118 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.48%
- matrix_size_y: 0.35%
- p1: 9.87%
- p2: 0.22%
- p3: 70.25%
- p4: 5.23%
- p5: 4.31%
- p6: 2.24%
- p7: 0.64%
- p8: 1.40%

---

### Bagging

#### Performance Metrics
- MSE: 5.070e-310
- Training Time: 23.488 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.41%
- matrix_size_y: 0.37%
- p1: 9.64%
- p2: 0.22%
- p3: 70.52%
- p4: 5.55%
- p5: 4.23%
- p6: 2.27%
- p7: 0.52%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.660e-310
- Training Time: 8.682 seconds
- Evaluation Time: 0.110 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.47%
- matrix_size_y: 0.33%
- p1: 9.96%
- p2: 0.25%
- p3: 70.13%
- p4: 5.33%
- p5: 4.17%
- p6: 2.36%
- p7: 0.59%
- p8: 1.41%

---

### Bagging

#### Performance Metrics
- MSE: 5.125e-310
- Training Time: 8.720 seconds
- Evaluation Time: 0.110 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.58%
- matrix_size_y: 0.42%
- p1: 9.91%
- p2: 0.25%
- p3: 70.14%
- p4: 5.28%
- p5: 4.20%
- p6: 2.42%
- p7: 0.54%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 5.185e-310
- Training Time: 8.660 seconds
- Evaluation Time: 0.113 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.37%
- matrix_size_y: 0.35%
- p1: 9.94%
- p2: 0.22%
- p3: 69.98%
- p4: 5.73%
- p5: 4.23%
- p6: 2.39%
- p7: 0.48%
- p8: 1.31%

---

### Bagging

#### Performance Metrics
- MSE: 4.642e-310
- Training Time: 6.095 seconds
- Evaluation Time: 0.130 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.16%
- matrix_size_y: 0.36%
- p1: 9.64%
- p2: 0.21%
- p3: 70.70%
- p4: 5.61%
- p5: 4.39%
- p6: 2.20%
- p7: 0.45%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 5.269e-310
- Training Time: 6.083 seconds
- Evaluation Time: 0.128 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.50%
- matrix_size_y: 0.35%
- p1: 9.80%
- p2: 0.27%
- p3: 70.73%
- p4: 5.36%
- p5: 4.09%
- p6: 1.98%
- p7: 0.56%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 4.938e-310
- Training Time: 6.075 seconds
- Evaluation Time: 0.130 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.52%
- matrix_size_y: 0.39%
- p1: 10.12%
- p2: 0.24%
- p3: 69.77%
- p4: 5.07%
- p5: 4.52%
- p6: 2.56%
- p7: 0.52%
- p8: 1.29%

---

### Bagging

#### Performance Metrics
- MSE: 4.941e-310
- Training Time: 4.869 seconds
- Evaluation Time: 0.132 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.26%
- matrix_size_y: 0.36%
- p1: 9.96%
- p2: 0.23%
- p3: 70.30%
- p4: 5.35%
- p5: 4.31%
- p6: 2.29%
- p7: 0.61%
- p8: 1.32%

---

### Bagging

#### Performance Metrics
- MSE: 4.653e-310
- Training Time: 4.871 seconds
- Evaluation Time: 0.136 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.59%
- matrix_size_y: 0.33%
- p1: 9.86%
- p2: 0.23%
- p3: 70.47%
- p4: 5.37%
- p5: 4.15%
- p6: 2.19%
- p7: 0.59%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 4.842e-310
- Training Time: 4.833 seconds
- Evaluation Time: 0.137 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.54%
- matrix_size_y: 0.31%
- p1: 10.20%
- p2: 0.26%
- p3: 70.45%
- p4: 5.13%
- p5: 4.03%
- p6: 2.32%
- p7: 0.61%
- p8: 1.15%

---

### Bagging

#### Performance Metrics
- MSE: 5.440e-310
- Training Time: 4.766 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.41%
- matrix_size_y: 0.38%
- p1: 10.10%
- p2: 0.22%
- p3: 70.62%
- p4: 5.16%
- p5: 4.38%
- p6: 2.07%
- p7: 0.53%
- p8: 1.13%

---

### Bagging

#### Performance Metrics
- MSE: 5.312e-310
- Training Time: 4.723 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.31%
- p1: 9.84%
- p2: 0.22%
- p3: 70.15%
- p4: 5.27%
- p5: 4.50%
- p6: 2.43%
- p7: 0.63%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 5.273e-310
- Training Time: 4.718 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.02%
- matrix_size_y: 0.34%
- p1: 10.24%
- p2: 0.25%
- p3: 70.32%
- p4: 5.11%
- p5: 4.51%
- p6: 2.39%
- p7: 0.56%
- p8: 1.25%

---

### Bagging

#### Performance Metrics
- MSE: 5.111e-310
- Training Time: 4.751 seconds
- Evaluation Time: 0.149 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.20%
- matrix_size_y: 0.36%
- p1: 9.96%
- p2: 0.23%
- p3: 69.99%
- p4: 5.35%
- p5: 4.90%
- p6: 2.39%
- p7: 0.50%
- p8: 1.13%

---

### Bagging

#### Performance Metrics
- MSE: 5.193e-310
- Training Time: 4.697 seconds
- Evaluation Time: 0.147 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.61%
- matrix_size_y: 0.34%
- p1: 9.67%
- p2: 0.20%
- p3: 70.25%
- p4: 5.50%
- p5: 4.05%
- p6: 2.34%
- p7: 0.62%
- p8: 1.43%

---

### Bagging

#### Performance Metrics
- MSE: 5.230e-310
- Training Time: 4.759 seconds
- Evaluation Time: 0.148 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.51%
- matrix_size_y: 0.35%
- p1: 9.93%
- p2: 0.22%
- p3: 70.51%
- p4: 5.35%
- p5: 4.25%
- p6: 2.30%
- p7: 0.54%
- p8: 1.05%

---

### Bagging

#### Performance Metrics
- MSE: 5.425e-310
- Training Time: 54.746 seconds
- Evaluation Time: 0.162 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.70%
- matrix_size_y: 0.59%
- p1: 6.32%
- p2: 0.52%
- p3: 22.61%
- p4: 18.45%
- p5: 32.05%
- p6: 7.40%
- p7: 0.79%
- p8: 3.57%

---

### Bagging

#### Performance Metrics
- MSE: 5.066e-310
- Training Time: 54.591 seconds
- Evaluation Time: 0.160 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.16%
- matrix_size_y: 0.60%
- p1: 6.14%
- p2: 0.50%
- p3: 22.98%
- p4: 18.74%
- p5: 31.20%
- p6: 7.46%
- p7: 0.74%
- p8: 3.48%

---

### Bagging

#### Performance Metrics
- MSE: 4.883e-310
- Training Time: 58.591 seconds
- Evaluation Time: 0.163 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.60%
- matrix_size_y: 0.53%
- p1: 6.19%
- p2: 0.44%
- p3: 23.12%
- p4: 18.87%
- p5: 31.17%
- p6: 7.77%
- p7: 0.79%
- p8: 3.52%

---

### Bagging

#### Performance Metrics
- MSE: 4.760e-310
- Training Time: 26.329 seconds
- Evaluation Time: 0.162 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.84%
- matrix_size_y: 0.48%
- p1: 6.42%
- p2: 0.49%
- p3: 22.42%
- p4: 18.27%
- p5: 32.27%
- p6: 7.84%
- p7: 0.70%
- p8: 3.26%

---

### Bagging

#### Performance Metrics
- MSE: 5.386e-310
- Training Time: 26.007 seconds
- Evaluation Time: 0.165 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.34%
- matrix_size_y: 0.50%
- p1: 6.29%
- p2: 0.45%
- p3: 22.56%
- p4: 19.34%
- p5: 30.69%
- p6: 7.66%
- p7: 0.76%
- p8: 3.41%

---

### Bagging

#### Performance Metrics
- MSE: 5.014e-310
- Training Time: 26.332 seconds
- Evaluation Time: 0.165 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.93%
- matrix_size_y: 0.51%
- p1: 6.45%
- p2: 0.45%
- p3: 23.27%
- p4: 18.60%
- p5: 31.02%
- p6: 7.80%
- p7: 0.73%
- p8: 3.25%

---

### Bagging

#### Performance Metrics
- MSE: 5.153e-310
- Training Time: 17.852 seconds
- Evaluation Time: 0.170 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.85%
- matrix_size_y: 0.54%
- p1: 6.29%
- p2: 0.58%
- p3: 22.00%
- p4: 19.20%
- p5: 31.06%
- p6: 8.19%
- p7: 0.84%
- p8: 3.45%

---

### Bagging

#### Performance Metrics
- MSE: 4.913e-310
- Training Time: 17.899 seconds
- Evaluation Time: 0.169 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.74%
- matrix_size_y: 0.51%
- p1: 5.87%
- p2: 0.47%
- p3: 23.43%
- p4: 18.51%
- p5: 31.55%
- p6: 7.64%
- p7: 0.71%
- p8: 3.56%

---

### Bagging

#### Performance Metrics
- MSE: 5.502e-310
- Training Time: 17.902 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.08%
- matrix_size_y: 0.62%
- p1: 6.62%
- p2: 0.47%
- p3: 22.55%
- p4: 19.52%
- p5: 30.94%
- p6: 7.06%
- p7: 0.69%
- p8: 3.46%

---

### Bagging

#### Performance Metrics
- MSE: 5.158e-310
- Training Time: 13.725 seconds
- Evaluation Time: 0.176 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.27%
- matrix_size_y: 0.48%
- p1: 6.67%
- p2: 0.46%
- p3: 22.37%
- p4: 18.32%
- p5: 31.79%
- p6: 7.56%
- p7: 0.71%
- p8: 3.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.234e-310
- Training Time: 13.542 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.90%
- matrix_size_y: 0.51%
- p1: 6.72%
- p2: 0.43%
- p3: 23.07%
- p4: 18.55%
- p5: 31.39%
- p6: 7.31%
- p7: 0.71%
- p8: 3.41%

---

### Bagging

#### Performance Metrics
- MSE: 5.079e-310
- Training Time: 13.669 seconds
- Evaluation Time: 0.169 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.85%
- matrix_size_y: 0.49%
- p1: 6.24%
- p2: 0.45%
- p3: 22.12%
- p4: 18.70%
- p5: 31.83%
- p6: 7.90%
- p7: 0.78%
- p8: 3.64%

---

### Bagging

#### Performance Metrics
- MSE: 5.413e-310
- Training Time: 13.244 seconds
- Evaluation Time: 0.187 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.07%
- matrix_size_y: 0.55%
- p1: 6.25%
- p2: 0.55%
- p3: 22.38%
- p4: 19.19%
- p5: 31.79%
- p6: 7.95%
- p7: 0.72%
- p8: 3.57%

---

### Bagging

#### Performance Metrics
- MSE: 5.281e-310
- Training Time: 13.267 seconds
- Evaluation Time: 0.210 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.10%
- matrix_size_y: 0.53%
- p1: 6.11%
- p2: 0.52%
- p3: 22.73%
- p4: 18.54%
- p5: 32.30%
- p6: 8.03%
- p7: 0.72%
- p8: 3.42%

---

### Bagging

#### Performance Metrics
- MSE: 4.802e-310
- Training Time: 13.233 seconds
- Evaluation Time: 0.187 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.26%
- matrix_size_y: 0.56%
- p1: 6.29%
- p2: 0.51%
- p3: 22.32%
- p4: 19.97%
- p5: 30.63%
- p6: 8.25%
- p7: 0.78%
- p8: 3.45%

---

### Bagging

#### Performance Metrics
- MSE: 4.702e-310
- Training Time: 13.136 seconds
- Evaluation Time: 0.190 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.54%
- matrix_size_y: 0.48%
- p1: 6.42%
- p2: 0.51%
- p3: 22.37%
- p4: 18.56%
- p5: 31.58%
- p6: 8.30%
- p7: 0.82%
- p8: 3.43%

---

### Bagging

#### Performance Metrics
- MSE: 4.730e-310
- Training Time: 13.108 seconds
- Evaluation Time: 0.192 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.19%
- matrix_size_y: 0.57%
- p1: 6.11%
- p2: 0.49%
- p3: 22.71%
- p4: 18.48%
- p5: 31.49%
- p6: 8.03%
- p7: 0.71%
- p8: 3.22%

---

### Bagging

#### Performance Metrics
- MSE: 5.479e-310
- Training Time: 13.071 seconds
- Evaluation Time: 0.188 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.29%
- matrix_size_y: 0.55%
- p1: 6.24%
- p2: 0.45%
- p3: 22.71%
- p4: 19.14%
- p5: 30.86%
- p6: 7.62%
- p7: 0.65%
- p8: 3.50%

---

### Boosting

#### Performance Metrics
- MSE: 5.204e-310
- Training Time: 3.370 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.86%
- p1: 24.72%
- p2: 0.94%
- p3: 16.21%
- p4: 13.22%
- p5: 12.98%
- p6: 8.19%
- p7: 2.44%
- p8: 5.21%

---

### Boosting

#### Performance Metrics
- MSE: 4.674e-310
- Training Time: 3.282 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.87%
- p1: 24.72%
- p2: 0.93%
- p3: 16.21%
- p4: 13.22%
- p5: 12.98%
- p6: 8.20%
- p7: 2.44%
- p8: 5.21%

---

### Boosting

#### Performance Metrics
- MSE: 5.296e-310
- Training Time: 3.276 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.87%
- p1: 24.72%
- p2: 0.93%
- p3: 16.20%
- p4: 13.22%
- p5: 12.99%
- p6: 8.18%
- p7: 2.45%
- p8: 5.22%

---

### Boosting

#### Performance Metrics
- MSE: 4.678e-310
- Training Time: 2.908 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.666e-310
- Training Time: 2.896 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.188e-310
- Training Time: 2.909 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.854e-310
- Training Time: 2.940 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.278e-310
- Training Time: 3.076 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.173e-310
- Training Time: 2.937 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.063e-310
- Training Time: 2.282 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.706e-310
- Training Time: 2.284 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.870e-310
- Training Time: 2.317 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.895e-310
- Training Time: 2.259 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.169e-310
- Training Time: 2.351 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.823e-310
- Training Time: 2.376 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.225e-310
- Training Time: 2.336 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.471e-310
- Training Time: 2.326 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.085e-310
- Training Time: 2.317 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.500e-310
- Training Time: 23.912 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.747e-310
- Training Time: 27.741 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.787e-310
- Training Time: 24.736 seconds
- Evaluation Time: 0.009 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.30%
- matrix_size_y: 1.05%
- p1: 7.23%
- p2: 0.67%
- p3: 24.30%
- p4: 16.36%
- p5: 26.14%
- p6: 10.14%
- p7: 1.81%
- p8: 3.99%

---

### Boosting

#### Performance Metrics
- MSE: 4.906e-310
- Training Time: 20.521 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.950e-310
- Training Time: 20.509 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.287e-310
- Training Time: 20.479 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.047e-310
- Training Time: 20.611 seconds
- Evaluation Time: 0.042 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.813e-310
- Training Time: 20.605 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.889e-310
- Training Time: 20.585 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.838e-310
- Training Time: 16.704 seconds
- Evaluation Time: 0.009 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.034e-310
- Training Time: 16.774 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.937e-310
- Training Time: 16.647 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.823e-310
- Training Time: 17.004 seconds
- Evaluation Time: 0.009 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.065e-310
- Training Time: 17.032 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.729e-310
- Training Time: 16.914 seconds
- Evaluation Time: 0.009 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.812e-310
- Training Time: 17.190 seconds
- Evaluation Time: 0.009 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.217e-310
- Training Time: 17.255 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.214e-310
- Training Time: 17.115 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.172 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.053 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.054 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.674e-310
- Training Time: 3.814 seconds
- Evaluation Time: 0.104 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.24%
- p1: 7.15%
- p2: 0.84%
- p3: 36.31%
- p4: 22.59%
- p5: 6.32%
- p6: 6.52%
- p7: 4.38%
- p8: 4.28%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.831e-310
- Training Time: 3.786 seconds
- Evaluation Time: 0.102 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.24%
- p1: 7.15%
- p2: 0.84%
- p3: 36.31%
- p4: 22.59%
- p5: 6.32%
- p6: 6.52%
- p7: 4.38%
- p8: 4.28%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.998e-310
- Training Time: 3.811 seconds
- Evaluation Time: 0.104 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.24%
- p1: 7.15%
- p2: 0.84%
- p3: 36.31%
- p4: 22.59%
- p5: 6.32%
- p6: 6.52%
- p7: 4.38%
- p8: 4.28%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.927e-310
- Training Time: 11.433 seconds
- Evaluation Time: 0.053 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129590465348408.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.46%
- matrix_size_y: 1.33%
- p1: 7.15%
- p2: 0.80%
- p3: 36.33%
- p4: 22.47%
- p5: 6.16%
- p6: 6.83%
- p7: 4.18%
- p8: 4.29%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.117e-310
- Training Time: 0.020 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 139020841993016.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.665e-310
- Training Time: 0.027 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130637051151160.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.224e-310
- Training Time: 9.778 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 123869222880056.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.51%
- matrix_size_y: 1.32%
- p1: 7.37%
- p2: 0.80%
- p3: 36.22%
- p4: 22.72%
- p5: 6.18%
- p6: 6.46%
- p7: 4.25%
- p8: 4.18%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.813e-310
- Training Time: 0.022 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136392854684472.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.109e-310
- Training Time: 0.023 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 134965218460472.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.706e-310
- Training Time: 11.242 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 135681620263736.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.63%
- matrix_size_y: 1.35%
- p1: 7.35%
- p2: 0.73%
- p3: 36.07%
- p4: 22.50%
- p5: 6.18%
- p6: 6.58%
- p7: 4.27%
- p8: 4.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.652e-310
- Training Time: 11.106 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.58%
- matrix_size_y: 1.36%
- p1: 7.08%
- p2: 0.77%
- p3: 36.33%
- p4: 22.53%
- p5: 6.34%
- p6: 6.58%
- p7: 4.13%
- p8: 4.30%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.760e-310
- Training Time: 9.923 seconds
- Evaluation Time: 0.027 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.64%
- matrix_size_y: 1.26%
- p1: 7.25%
- p2: 0.74%
- p3: 36.37%
- p4: 22.47%
- p5: 6.25%
- p6: 6.49%
- p7: 4.27%
- p8: 4.27%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.095e-310
- Training Time: 12.154 seconds
- Evaluation Time: 0.025 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.51%
- matrix_size_y: 1.32%
- p1: 7.26%
- p2: 0.79%
- p3: 36.42%
- p4: 22.58%
- p5: 6.29%
- p6: 6.40%
- p7: 4.18%
- p8: 4.26%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.169e-310
- Training Time: 11.070 seconds
- Evaluation Time: 0.023 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.51%
- matrix_size_y: 1.25%
- p1: 7.30%
- p2: 0.80%
- p3: 36.23%
- p4: 22.49%
- p5: 6.25%
- p6: 6.68%
- p7: 4.31%
- p8: 4.17%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.688e-310
- Training Time: 11.476 seconds
- Evaluation Time: 0.024 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.37%
- matrix_size_y: 1.40%
- p1: 7.19%
- p2: 0.77%
- p3: 36.26%
- p4: 22.36%
- p5: 6.38%
- p6: 6.70%
- p7: 4.26%
- p8: 4.31%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.047e-310
- Training Time: 0.024 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 128446311646008.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.420e-310
- Training Time: 13.232 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.34%
- matrix_size_y: 1.35%
- p1: 7.21%
- p2: 0.74%
- p3: 36.19%
- p4: 22.59%
- p5: 6.22%
- p6: 6.59%
- p7: 4.39%
- p8: 4.38%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.497e-310
- Training Time: 10.889 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.29%
- matrix_size_y: 1.25%
- p1: 7.30%
- p2: 0.83%
- p3: 36.48%
- p4: 22.60%
- p5: 6.20%
- p6: 6.44%
- p7: 4.30%
- p8: 4.31%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 5.131e-04
- Training Time: 0.105 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.97%
- matrix_size_y: 0.32%
- p1: 2.17%
- p2: 0.75%
- p3: 74.36%
- p4: 5.88%
- p5: 1.16%
- p6: 11.87%
- p7: 1.07%
- p8: 1.44%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.997e-04
- Training Time: 0.064 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.06%
- matrix_size_y: 0.32%
- p1: 2.19%
- p2: 0.75%
- p3: 74.37%
- p4: 5.86%
- p5: 1.16%
- p6: 11.85%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.830e-04
- Training Time: 0.067 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.97%
- matrix_size_y: 0.40%
- p1: 2.12%
- p2: 0.75%
- p3: 74.42%
- p4: 5.88%
- p5: 1.17%
- p6: 11.75%
- p7: 1.17%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.028 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.028 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.538e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.90%
- matrix_size_y: 0.31%
- p1: 2.08%
- p2: 0.23%
- p3: 79.84%
- p4: 7.44%
- p5: 1.01%
- p6: 6.65%
- p7: 0.71%
- p8: 0.84%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.538e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.90%
- matrix_size_y: 0.31%
- p1: 2.08%
- p2: 0.23%
- p3: 79.84%
- p4: 7.44%
- p5: 1.01%
- p6: 6.65%
- p7: 0.71%
- p8: 0.84%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.538e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.90%
- matrix_size_y: 0.31%
- p1: 2.08%
- p2: 0.23%
- p3: 79.84%
- p4: 7.44%
- p5: 1.01%
- p6: 6.65%
- p7: 0.71%
- p8: 0.84%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.043 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.043 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 8.546e-05
- Training Time: 0.052 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.54%
- matrix_size_y: 0.20%
- p1: 10.01%
- p2: 0.22%
- p3: 71.13%
- p4: 4.93%
- p5: 4.22%
- p6: 1.91%
- p7: 0.98%
- p8: 1.85%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 8.546e-05
- Training Time: 0.052 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.54%
- matrix_size_y: 0.20%
- p1: 10.01%
- p2: 0.22%
- p3: 71.13%
- p4: 4.93%
- p5: 4.22%
- p6: 1.91%
- p7: 0.98%
- p8: 1.85%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 8.546e-05
- Training Time: 0.053 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.54%
- matrix_size_y: 0.20%
- p1: 10.01%
- p2: 0.22%
- p3: 71.13%
- p4: 4.93%
- p5: 4.22%
- p6: 1.91%
- p7: 0.98%
- p8: 1.85%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.063 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.023e-310
- Training Time: 13.506 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.41%
- matrix_size_y: 0.56%
- p1: 3.23%
- p2: 0.46%
- p3: 77.83%
- p4: 5.57%
- p5: 1.08%
- p6: 8.04%
- p7: 0.81%
- p8: 1.02%

---

### Bagging

#### Performance Metrics
- MSE: 5.369e-310
- Training Time: 11.617 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.51%
- matrix_size_y: 0.47%
- p1: 3.00%
- p2: 0.45%
- p3: 77.64%
- p4: 5.48%
- p5: 0.93%
- p6: 8.72%
- p7: 0.87%
- p8: 0.93%

---

### Bagging

#### Performance Metrics
- MSE: 5.316e-310
- Training Time: 11.196 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.39%
- matrix_size_y: 0.41%
- p1: 3.37%
- p2: 0.55%
- p3: 77.77%
- p4: 6.58%
- p5: 1.16%
- p6: 7.01%
- p7: 0.96%
- p8: 0.80%

---

### Bagging

#### Performance Metrics
- MSE: 5.266e-310
- Training Time: 2.848 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.29%
- matrix_size_y: 0.42%
- p1: 3.68%
- p2: 0.41%
- p3: 78.23%
- p4: 5.83%
- p5: 0.97%
- p6: 7.23%
- p7: 0.78%
- p8: 1.16%

---

### Bagging

#### Performance Metrics
- MSE: 4.974e-310
- Training Time: 2.760 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.28%
- matrix_size_y: 0.33%
- p1: 3.33%
- p2: 0.34%
- p3: 77.82%
- p4: 6.05%
- p5: 1.22%
- p6: 7.45%
- p7: 0.85%
- p8: 1.33%

---

### Bagging

#### Performance Metrics
- MSE: 5.027e-310
- Training Time: 2.791 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.40%
- matrix_size_y: 0.36%
- p1: 2.96%
- p2: 0.40%
- p3: 77.86%
- p4: 5.58%
- p5: 1.18%
- p6: 8.29%
- p7: 0.78%
- p8: 1.18%

---

### Bagging

#### Performance Metrics
- MSE: 5.390e-310
- Training Time: 2.999 seconds
- Evaluation Time: 0.071 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.46%
- matrix_size_y: 0.53%
- p1: 2.61%
- p2: 0.35%
- p3: 78.88%
- p4: 5.16%
- p5: 1.57%
- p6: 7.46%
- p7: 0.96%
- p8: 1.02%

---

### Bagging

#### Performance Metrics
- MSE: 4.887e-310
- Training Time: 3.007 seconds
- Evaluation Time: 0.069 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.35%
- matrix_size_y: 0.41%
- p1: 3.11%
- p2: 0.34%
- p3: 78.37%
- p4: 5.32%
- p5: 1.36%
- p6: 7.69%
- p7: 0.81%
- p8: 1.25%

---

### Bagging

#### Performance Metrics
- MSE: 4.736e-310
- Training Time: 3.042 seconds
- Evaluation Time: 0.086 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.33%
- matrix_size_y: 0.43%
- p1: 3.29%
- p2: 0.34%
- p3: 78.35%
- p4: 5.24%
- p5: 1.42%
- p6: 7.50%
- p7: 0.80%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 5.331e-310
- Training Time: 3.207 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.55%
- matrix_size_y: 0.46%
- p1: 10.31%
- p2: 0.27%
- p3: 73.20%
- p4: 4.87%
- p5: 2.90%
- p6: 2.19%
- p7: 0.79%
- p8: 1.47%

---

### Bagging

#### Performance Metrics
- MSE: 4.852e-310
- Training Time: 3.193 seconds
- Evaluation Time: 0.094 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.55%
- matrix_size_y: 0.37%
- p1: 10.58%
- p2: 0.26%
- p3: 72.48%
- p4: 4.76%
- p5: 3.70%
- p6: 2.23%
- p7: 0.95%
- p8: 1.11%

---

### Bagging

#### Performance Metrics
- MSE: 4.647e-310
- Training Time: 3.227 seconds
- Evaluation Time: 0.095 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.91%
- matrix_size_y: 0.53%
- p1: 10.26%
- p2: 0.26%
- p3: 73.00%
- p4: 4.56%
- p5: 3.08%
- p6: 2.38%
- p7: 0.65%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.333e-310
- Training Time: 3.953 seconds
- Evaluation Time: 0.125 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.11%
- matrix_size_y: 0.36%
- p1: 10.05%
- p2: 0.22%
- p3: 69.88%
- p4: 4.95%
- p5: 4.55%
- p6: 2.50%
- p7: 0.86%
- p8: 1.50%

---

### Bagging

#### Performance Metrics
- MSE: 5.071e-310
- Training Time: 3.922 seconds
- Evaluation Time: 0.127 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.81%
- matrix_size_y: 0.44%
- p1: 9.91%
- p2: 0.24%
- p3: 70.78%
- p4: 5.24%
- p5: 4.21%
- p6: 2.34%
- p7: 0.67%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.477e-310
- Training Time: 3.959 seconds
- Evaluation Time: 0.128 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.25%
- matrix_size_y: 0.28%
- p1: 9.76%
- p2: 0.23%
- p3: 71.19%
- p4: 4.86%
- p5: 3.72%
- p6: 2.57%
- p7: 0.74%
- p8: 1.40%

---

### Bagging

#### Performance Metrics
- MSE: 4.803e-310
- Training Time: 4.680 seconds
- Evaluation Time: 0.151 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.39%
- matrix_size_y: 0.32%
- p1: 9.70%
- p2: 0.21%
- p3: 70.40%
- p4: 5.54%
- p5: 4.09%
- p6: 2.45%
- p7: 0.58%
- p8: 1.33%

---

### Bagging

#### Performance Metrics
- MSE: 5.101e-310
- Training Time: 4.692 seconds
- Evaluation Time: 0.149 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 0.37%
- p1: 9.76%
- p2: 0.21%
- p3: 70.34%
- p4: 5.28%
- p5: 4.68%
- p6: 2.38%
- p7: 0.53%
- p8: 1.13%

---

### Bagging

#### Performance Metrics
- MSE: 5.009e-310
- Training Time: 4.676 seconds
- Evaluation Time: 0.149 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.27%
- matrix_size_y: 0.47%
- p1: 10.06%
- p2: 0.23%
- p3: 70.40%
- p4: 5.22%
- p5: 4.40%
- p6: 2.22%
- p7: 0.56%
- p8: 1.17%

---

### Bagging

#### Performance Metrics
- MSE: 5.490e-310
- Training Time: 14.011 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 4.42%
- matrix_size_y: 1.33%
- p1: 8.63%
- p2: 1.62%
- p3: 36.48%
- p4: 27.10%
- p5: 4.65%
- p6: 10.31%
- p7: 1.37%
- p8: 4.10%

---

### Bagging

#### Performance Metrics
- MSE: 4.896e-310
- Training Time: 14.460 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.31%
- matrix_size_y: 1.77%
- p1: 7.77%
- p2: 1.57%
- p3: 36.17%
- p4: 29.09%
- p5: 4.87%
- p6: 10.19%
- p7: 1.26%
- p8: 3.99%

---

### Bagging

#### Performance Metrics
- MSE: 5.167e-310
- Training Time: 14.702 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.07%
- matrix_size_y: 1.11%
- p1: 8.90%
- p2: 1.49%
- p3: 35.70%
- p4: 27.69%
- p5: 5.00%
- p6: 11.13%
- p7: 1.77%
- p8: 4.15%

---

### Bagging

#### Performance Metrics
- MSE: 5.075e-310
- Training Time: 8.710 seconds
- Evaluation Time: 0.045 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.32%
- matrix_size_y: 0.89%
- p1: 7.69%
- p2: 1.00%
- p3: 38.50%
- p4: 27.95%
- p5: 6.17%
- p6: 8.08%
- p7: 1.68%
- p8: 4.72%

---

### Bagging

#### Performance Metrics
- MSE: 4.661e-310
- Training Time: 8.773 seconds
- Evaluation Time: 0.043 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.61%
- matrix_size_y: 0.93%
- p1: 8.22%
- p2: 1.08%
- p3: 38.71%
- p4: 28.00%
- p5: 4.88%
- p6: 8.47%
- p7: 1.57%
- p8: 4.54%

---

### Bagging

#### Performance Metrics
- MSE: 4.713e-310
- Training Time: 8.714 seconds
- Evaluation Time: 0.043 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.49%
- matrix_size_y: 0.90%
- p1: 8.42%
- p2: 1.16%
- p3: 37.83%
- p4: 27.98%
- p5: 5.60%
- p6: 8.50%
- p7: 1.65%
- p8: 4.48%

---

### Bagging

#### Performance Metrics
- MSE: 4.780e-310
- Training Time: 9.406 seconds
- Evaluation Time: 0.084 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.68%
- matrix_size_y: 0.81%
- p1: 9.09%
- p2: 0.93%
- p3: 38.49%
- p4: 27.05%
- p5: 5.41%
- p6: 8.52%
- p7: 1.44%
- p8: 4.58%

---

### Bagging

#### Performance Metrics
- MSE: 5.502e-310
- Training Time: 9.477 seconds
- Evaluation Time: 0.086 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.70%
- matrix_size_y: 0.91%
- p1: 8.26%
- p2: 0.93%
- p3: 38.81%
- p4: 27.21%
- p5: 6.01%
- p6: 8.02%
- p7: 1.43%
- p8: 4.73%

---

### Bagging

#### Performance Metrics
- MSE: 4.667e-310
- Training Time: 9.360 seconds
- Evaluation Time: 0.083 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.91%
- matrix_size_y: 0.79%
- p1: 8.52%
- p2: 0.82%
- p3: 38.77%
- p4: 27.72%
- p5: 5.92%
- p6: 7.18%
- p7: 1.47%
- p8: 4.89%

---

### Bagging

#### Performance Metrics
- MSE: 4.857e-310
- Training Time: 8.861 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 16.71%
- matrix_size_y: 0.76%
- p1: 18.00%
- p2: 0.69%
- p3: 19.50%
- p4: 21.22%
- p5: 10.38%
- p6: 7.91%
- p7: 0.95%
- p8: 3.87%

---

### Bagging

#### Performance Metrics
- MSE: 5.238e-310
- Training Time: 8.888 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 10.83%
- matrix_size_y: 0.75%
- p1: 21.84%
- p2: 0.67%
- p3: 19.64%
- p4: 20.49%
- p5: 12.77%
- p6: 7.90%
- p7: 0.97%
- p8: 4.15%

---

### Bagging

#### Performance Metrics
- MSE: 5.459e-310
- Training Time: 8.857 seconds
- Evaluation Time: 0.118 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 12.72%
- matrix_size_y: 0.85%
- p1: 20.44%
- p2: 0.76%
- p3: 19.82%
- p4: 21.95%
- p5: 10.21%
- p6: 7.88%
- p7: 1.04%
- p8: 4.33%

---

### Bagging

#### Performance Metrics
- MSE: 4.642e-310
- Training Time: 10.941 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 12.48%
- matrix_size_y: 0.59%
- p1: 20.34%
- p2: 0.54%
- p3: 23.64%
- p4: 20.04%
- p5: 11.91%
- p6: 6.25%
- p7: 0.81%
- p8: 3.40%

---

### Bagging

#### Performance Metrics
- MSE: 5.235e-310
- Training Time: 10.934 seconds
- Evaluation Time: 0.167 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 12.49%
- matrix_size_y: 0.58%
- p1: 18.73%
- p2: 0.57%
- p3: 23.82%
- p4: 20.91%
- p5: 12.14%
- p6: 6.60%
- p7: 0.74%
- p8: 3.44%

---

### Bagging

#### Performance Metrics
- MSE: 5.364e-310
- Training Time: 10.934 seconds
- Evaluation Time: 0.173 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 11.61%
- matrix_size_y: 0.55%
- p1: 20.73%
- p2: 0.57%
- p3: 24.57%
- p4: 20.52%
- p5: 10.68%
- p6: 6.75%
- p7: 0.75%
- p8: 3.26%

---

### Bagging

#### Performance Metrics
- MSE: 5.147e-310
- Training Time: 13.089 seconds
- Evaluation Time: 0.191 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.51%
- matrix_size_y: 0.56%
- p1: 6.07%
- p2: 0.56%
- p3: 22.28%
- p4: 19.27%
- p5: 31.80%
- p6: 7.87%
- p7: 0.74%
- p8: 3.36%

---

### Bagging

#### Performance Metrics
- MSE: 4.985e-310
- Training Time: 13.082 seconds
- Evaluation Time: 0.193 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.35%
- matrix_size_y: 0.47%
- p1: 6.38%
- p2: 0.47%
- p3: 22.73%
- p4: 18.23%
- p5: 32.48%
- p6: 7.91%
- p7: 0.74%
- p8: 3.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.338e-310
- Training Time: 13.097 seconds
- Evaluation Time: 0.189 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.23%
- matrix_size_y: 0.48%
- p1: 6.17%
- p2: 0.47%
- p3: 22.89%
- p4: 19.36%
- p5: 31.61%
- p6: 7.71%
- p7: 0.73%
- p8: 3.36%

---

### Boosting

#### Performance Metrics
- MSE: 5.266e-310
- Training Time: 1.319 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.765e-310
- Training Time: 1.282 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.310e-310
- Training Time: 1.305 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.361e-310
- Training Time: 0.827 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 4.924e-310
- Training Time: 0.828 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.429e-310
- Training Time: 0.828 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.038e-310
- Training Time: 1.445 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 1.41%
- p1: 8.87%
- p2: 1.06%
- p3: 34.54%
- p4: 20.82%
- p5: 5.86%
- p6: 16.57%
- p7: 2.22%
- p8: 3.33%

---

### Boosting

#### Performance Metrics
- MSE: 4.957e-310
- Training Time: 1.437 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 1.41%
- p1: 8.87%
- p2: 1.06%
- p3: 34.54%
- p4: 20.82%
- p5: 5.86%
- p6: 16.57%
- p7: 2.22%
- p8: 3.33%

---

### Boosting

#### Performance Metrics
- MSE: 5.293e-310
- Training Time: 1.449 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 1.41%
- p1: 8.87%
- p2: 1.06%
- p3: 34.54%
- p4: 20.82%
- p5: 5.86%
- p6: 16.57%
- p7: 2.22%
- p8: 3.33%

---

### Boosting

#### Performance Metrics
- MSE: 4.781e-310
- Training Time: 1.548 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.329e-310
- Training Time: 1.573 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 4.798e-310
- Training Time: 1.599 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 4.971e-310
- Training Time: 1.870 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.96%
- matrix_size_y: 1.53%
- p1: 23.98%
- p2: 1.10%
- p3: 16.08%
- p4: 12.79%
- p5: 11.82%
- p6: 9.08%
- p7: 2.84%
- p8: 5.81%

---

### Boosting

#### Performance Metrics
- MSE: 4.997e-310
- Training Time: 1.913 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.96%
- matrix_size_y: 1.53%
- p1: 23.98%
- p2: 1.10%
- p3: 16.08%
- p4: 12.79%
- p5: 11.82%
- p6: 9.08%
- p7: 2.84%
- p8: 5.81%

---

### Boosting

#### Performance Metrics
- MSE: 5.418e-310
- Training Time: 1.886 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.96%
- matrix_size_y: 1.53%
- p1: 23.98%
- p2: 1.10%
- p3: 16.08%
- p4: 12.79%
- p5: 11.82%
- p6: 9.08%
- p7: 2.84%
- p8: 5.81%

---

### Boosting

#### Performance Metrics
- MSE: 4.642e-310
- Training Time: 2.319 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.457e-310
- Training Time: 2.420 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.028e-310
- Training Time: 2.306 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.744e-310
- Training Time: 6.890 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.88%
- matrix_size_y: 2.08%
- p1: 7.91%
- p2: 1.30%
- p3: 34.74%
- p4: 25.57%
- p5: 5.96%
- p6: 11.43%
- p7: 2.46%
- p8: 4.67%

---

### Boosting

#### Performance Metrics
- MSE: 4.723e-310
- Training Time: 7.197 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 4.25%
- matrix_size_y: 2.04%
- p1: 8.13%
- p2: 1.47%
- p3: 34.93%
- p4: 24.01%
- p5: 5.74%
- p6: 12.07%
- p7: 2.51%
- p8: 4.84%

---

### Boosting

#### Performance Metrics
- MSE: 4.969e-310
- Training Time: 6.855 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 3.83%
- matrix_size_y: 1.95%
- p1: 8.18%
- p2: 1.46%
- p3: 34.18%
- p4: 25.43%
- p5: 6.52%
- p6: 11.06%
- p7: 2.22%
- p8: 5.16%

---

### Boosting

#### Performance Metrics
- MSE: 5.346e-310
- Training Time: 8.782 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 4.74%
- matrix_size_y: 1.61%
- p1: 8.32%
- p2: 1.37%
- p3: 34.55%
- p4: 24.11%
- p5: 7.08%
- p6: 9.27%
- p7: 4.17%
- p8: 4.78%

---

### Boosting

#### Performance Metrics
- MSE: 5.228e-310
- Training Time: 8.771 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 4.74%
- matrix_size_y: 1.61%
- p1: 8.32%
- p2: 1.37%
- p3: 34.55%
- p4: 24.11%
- p5: 7.08%
- p6: 9.27%
- p7: 4.17%
- p8: 4.78%

---

### Boosting

#### Performance Metrics
- MSE: 4.689e-310
- Training Time: 8.778 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 4.74%
- matrix_size_y: 1.61%
- p1: 8.32%
- p2: 1.37%
- p3: 34.55%
- p4: 24.11%
- p5: 7.08%
- p6: 9.27%
- p7: 4.17%
- p8: 4.78%

---

### Boosting

#### Performance Metrics
- MSE: 5.403e-310
- Training Time: 10.800 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 5.61%
- matrix_size_y: 1.71%
- p1: 8.15%
- p2: 1.11%
- p3: 36.21%
- p4: 24.05%
- p5: 6.62%
- p6: 9.13%
- p7: 2.41%
- p8: 5.01%

---

### Boosting

#### Performance Metrics
- MSE: 5.178e-310
- Training Time: 10.813 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 5.61%
- matrix_size_y: 1.71%
- p1: 8.15%
- p2: 1.11%
- p3: 36.21%
- p4: 24.05%
- p5: 6.62%
- p6: 9.13%
- p7: 2.41%
- p8: 5.01%

---

### Boosting

#### Performance Metrics
- MSE: 5.469e-310
- Training Time: 10.706 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 5.61%
- matrix_size_y: 1.71%
- p1: 8.15%
- p2: 1.11%
- p3: 36.21%
- p4: 24.05%
- p5: 6.62%
- p6: 9.13%
- p7: 2.41%
- p8: 5.01%

---

### Boosting

#### Performance Metrics
- MSE: 5.500e-310
- Training Time: 12.931 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 11.36%
- matrix_size_y: 1.24%
- p1: 17.45%
- p2: 1.09%
- p3: 20.22%
- p4: 19.04%
- p5: 11.45%
- p6: 11.20%
- p7: 2.43%
- p8: 4.52%

---

### Boosting

#### Performance Metrics
- MSE: 5.413e-310
- Training Time: 12.988 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 11.36%
- matrix_size_y: 1.24%
- p1: 17.45%
- p2: 1.09%
- p3: 20.22%
- p4: 19.04%
- p5: 11.45%
- p6: 11.20%
- p7: 2.43%
- p8: 4.52%

---

### Boosting

#### Performance Metrics
- MSE: 5.017e-310
- Training Time: 12.941 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 11.36%
- matrix_size_y: 1.24%
- p1: 17.45%
- p2: 1.09%
- p3: 20.22%
- p4: 19.04%
- p5: 11.45%
- p6: 11.20%
- p7: 2.43%
- p8: 4.52%

---

### Boosting

#### Performance Metrics
- MSE: 4.751e-310
- Training Time: 16.805 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 10.32%
- matrix_size_y: 0.94%
- p1: 17.68%
- p2: 0.79%
- p3: 23.16%
- p4: 21.89%
- p5: 9.29%
- p6: 9.81%
- p7: 2.05%
- p8: 4.07%

---

### Boosting

#### Performance Metrics
- MSE: 5.217e-310
- Training Time: 16.748 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 10.32%
- matrix_size_y: 0.94%
- p1: 17.68%
- p2: 0.79%
- p3: 23.16%
- p4: 21.89%
- p5: 9.29%
- p6: 9.81%
- p7: 2.05%
- p8: 4.07%

---

### Boosting

#### Performance Metrics
- MSE: 4.672e-310
- Training Time: 16.760 seconds
- Evaluation Time: 0.007 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 10.32%
- matrix_size_y: 0.94%
- p1: 17.68%
- p2: 0.79%
- p3: 23.16%
- p4: 21.89%
- p5: 9.29%
- p6: 9.81%
- p7: 2.05%
- p8: 4.07%

---

### Boosting

#### Performance Metrics
- MSE: 5.352e-310
- Training Time: 17.226 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 4.799e-310
- Training Time: 17.300 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### Boosting

#### Performance Metrics
- MSE: 5.346e-310
- Training Time: 17.267 seconds
- Evaluation Time: 0.008 seconds

#### Model Parameters
- criteria: 1.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 8.54%
- matrix_size_y: 1.20%
- p1: 7.67%
- p2: 0.64%
- p3: 23.86%
- p4: 16.44%
- p5: 25.91%
- p6: 10.14%
- p7: 1.86%
- p8: 3.74%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.042 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.041 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.041 seconds
- Evaluation Time: 0.010 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 34.56%
- F1: 9.65%
- F2: 533.08%
- F3: 258.60%
- F4: 44.96%
- F5: 171.66%
- F6: 39.97%
- F7: 38.56%
- F8: 29.21%
- F9: 11.27%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.066 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.065 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.065 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 76.65%
- F1: 11.45%
- F2: 1076.44%
- F3: 500.81%
- F4: 58.89%
- F5: 302.10%
- F6: 44.81%
- F7: 55.51%
- F8: 56.96%
- F9: 13.28%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.091 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 101.52%
- F1: 12.09%
- F2: 1654.31%
- F3: 766.43%
- F4: 73.40%
- F5: 469.74%
- F6: 47.77%
- F7: 83.06%
- F8: 87.62%
- F9: 18.96%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.091 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 101.52%
- F1: 12.09%
- F2: 1654.31%
- F3: 766.43%
- F4: 73.40%
- F5: 469.74%
- F6: 47.77%
- F7: 83.06%
- F8: 87.62%
- F9: 18.96%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.091 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 101.52%
- F1: 12.09%
- F2: 1654.31%
- F3: 766.43%
- F4: 73.40%
- F5: 469.74%
- F6: 47.77%
- F7: 83.06%
- F8: 87.62%
- F9: 18.96%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.115 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.116 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.116 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 443.55%
- F1: 43.72%
- F2: 1469.55%
- F3: 627.51%
- F4: 298.65%
- F5: 143.12%
- F6: 130.26%
- F7: 180.86%
- F8: 235.24%
- F9: 29.34%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.138 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 679.00%
- F1: 52.67%
- F2: 1640.71%
- F3: 720.77%
- F4: 433.20%
- F5: 156.95%
- F6: 176.13%
- F7: 216.47%
- F8: 296.02%
- F9: 37.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.138 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 679.00%
- F1: 52.67%
- F2: 1640.71%
- F3: 720.77%
- F4: 433.20%
- F5: 156.95%
- F6: 176.13%
- F7: 216.47%
- F8: 296.02%
- F9: 37.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.138 seconds
- Evaluation Time: 0.048 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 679.00%
- F1: 52.67%
- F2: 1640.71%
- F3: 720.77%
- F4: 433.20%
- F5: 156.95%
- F6: 176.13%
- F7: 216.47%
- F8: 296.02%
- F9: 37.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.161 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- colsample_bytree: 0.000
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 919.27%
- F1: 61.13%
- F2: 1717.59%
- F3: 790.36%
- F4: 554.36%
- F5: 173.01%
- F6: 217.66%
- F7: 248.86%
- F8: 343.77%
- F9: 44.82%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.026e-310
- Training Time: 0.005 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137520690447160.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.987e-310
- Training Time: 1.803 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.22%
- matrix_size_y: 1.70%
- p1: 3.43%
- p2: 1.32%
- p3: 35.23%
- p4: 27.46%
- p5: 5.09%
- p6: 13.82%
- p7: 5.18%
- p8: 3.56%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.281e-310
- Training Time: 1.809 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133551037563704.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.22%
- matrix_size_y: 1.70%
- p1: 3.43%
- p2: 1.32%
- p3: 35.23%
- p4: 27.46%
- p5: 5.09%
- p6: 13.82%
- p7: 5.18%
- p8: 3.56%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.326e-310
- Training Time: 0.011 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 140106195747640.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.815e-310
- Training Time: 7.285 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 134199200138040.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.43%
- matrix_size_y: 1.37%
- p1: 3.50%
- p2: 1.06%
- p3: 34.92%
- p4: 27.10%
- p5: 4.26%
- p6: 14.84%
- p7: 5.85%
- p8: 3.67%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.330e-310
- Training Time: 7.892 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.33%
- matrix_size_y: 1.43%
- p1: 3.72%
- p2: 1.03%
- p3: 34.82%
- p4: 26.86%
- p5: 4.18%
- p6: 14.75%
- p7: 6.10%
- p8: 3.78%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.207e-310
- Training Time: 6.027 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.92%
- matrix_size_y: 1.58%
- p1: 3.37%
- p2: 0.78%
- p3: 34.20%
- p4: 26.67%
- p5: 3.69%
- p6: 15.57%
- p7: 6.31%
- p8: 3.91%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.957e-310
- Training Time: 6.648 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 127829600060216.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.20%
- matrix_size_y: 1.81%
- p1: 3.39%
- p2: 0.80%
- p3: 34.13%
- p4: 26.23%
- p5: 3.76%
- p6: 15.41%
- p7: 6.37%
- p8: 3.90%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.240e-310
- Training Time: 6.990 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 136845380240184.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.91%
- matrix_size_y: 1.73%
- p1: 3.37%
- p2: 0.87%
- p3: 34.13%
- p4: 26.39%
- p5: 3.86%
- p6: 15.63%
- p7: 6.34%
- p8: 3.76%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.458e-310
- Training Time: 0.017 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 128828934931256.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.152e-310
- Training Time: 0.017 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 137848223646520.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.201e-310
- Training Time: 0.017 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126127094317880.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.978e-310
- Training Time: 11.106 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.16%
- matrix_size_y: 1.44%
- p1: 6.67%
- p2: 0.65%
- p3: 36.30%
- p4: 23.02%
- p5: 5.67%
- p6: 7.08%
- p7: 4.43%
- p8: 4.57%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.400e-310
- Training Time: 0.020 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 130584576213816.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.871e-310
- Training Time: 11.216 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 133352495989560.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.39%
- matrix_size_y: 1.17%
- p1: 6.64%
- p2: 0.70%
- p3: 36.31%
- p4: 22.60%
- p5: 5.63%
- p6: 7.37%
- p7: 4.54%
- p8: 4.65%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.799e-310
- Training Time: 12.236 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.34%
- matrix_size_y: 1.29%
- p1: 7.31%
- p2: 0.81%
- p3: 36.27%
- p4: 22.68%
- p5: 6.16%
- p6: 6.70%
- p7: 4.11%
- p8: 4.33%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.738e-310
- Training Time: 12.156 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.29%
- matrix_size_y: 1.34%
- p1: 7.16%
- p2: 0.75%
- p3: 36.25%
- p4: 22.43%
- p5: 6.36%
- p6: 6.73%
- p7: 4.37%
- p8: 4.33%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.807e-310
- Training Time: 11.719 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129586426233656.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.34%
- matrix_size_y: 1.20%
- p1: 7.30%
- p2: 0.80%
- p3: 36.11%
- p4: 22.53%
- p5: 6.24%
- p6: 6.45%
- p7: 4.65%
- p8: 4.39%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.790e-310
- Training Time: 0.021 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.000
- max_depth: -1413004528.000
- min_data_leaf: 138910714250040.000
- n_estimators: 1.000
- num_bins: -1413004528.000
- num_threads: 0.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.786e-310
- Training Time: 0.022 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.000
- max_depth: 455557904.000
- min_data_leaf: 132199548928824.000
- n_estimators: 1.000
- num_bins: 455557904.000
- num_threads: 0.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.895e-310
- Training Time: 0.786 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.000
- max_depth: -1394130024.000
- min_data_leaf: 0.000
- n_estimators: 1.000
- num_bins: -1394130064.000
- num_threads: 0.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.198e-310
- Training Time: 0.747 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- binning_method: 0.000
- learning_rate: 0.000
- max_depth: -1735965800.000
- min_data_leaf: 0.000
- n_estimators: 1.000
- num_bins: -1735965840.000
- num_threads: 0.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.764e-310
- Training Time: 0.522 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 20.000
- num_threads: 0.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.41%
- matrix_size_y: 1.00%
- p1: 3.48%
- p2: 0.33%
- p3: 37.22%
- p4: 26.59%
- p5: 2.70%
- p6: 15.25%
- p7: 5.70%
- p8: 3.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.896e-310
- Training Time: 0.795 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.70%
- matrix_size_y: 0.69%
- p1: 3.05%
- p2: 0.10%
- p3: 36.85%
- p4: 28.09%
- p5: 2.74%
- p6: 16.54%
- p7: 5.50%
- p8: 2.73%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.893e-310
- Training Time: 0.777 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 6.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.70%
- matrix_size_y: 0.69%
- p1: 3.05%
- p2: 0.10%
- p3: 36.85%
- p4: 28.09%
- p5: 2.74%
- p6: 16.54%
- p7: 5.50%
- p8: 2.73%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.857e-310
- Training Time: 3.880 seconds
- Evaluation Time: 0.102 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 125532786606904.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.24%
- p1: 7.15%
- p2: 0.84%
- p3: 36.31%
- p4: 22.59%
- p5: 6.32%
- p6: 6.52%
- p7: 4.38%
- p8: 4.28%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.029e-310
- Training Time: 3.869 seconds
- Evaluation Time: 0.104 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.24%
- p1: 7.15%
- p2: 0.84%
- p3: 36.31%
- p4: 22.59%
- p5: 6.32%
- p6: 6.52%
- p7: 4.38%
- p8: 4.28%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.504e-310
- Training Time: 3.866 seconds
- Evaluation Time: 0.103 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 129076283523896.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.24%
- p1: 7.15%
- p2: 0.84%
- p3: 36.31%
- p4: 22.59%
- p5: 6.32%
- p6: 6.52%
- p7: 4.38%
- p8: 4.28%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.020e-310
- Training Time: 10.938 seconds
- Evaluation Time: 0.053 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.36%
- matrix_size_y: 1.29%
- p1: 7.15%
- p2: 0.80%
- p3: 36.35%
- p4: 22.45%
- p5: 6.29%
- p6: 6.65%
- p7: 4.37%
- p8: 4.27%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.851e-310
- Training Time: 11.228 seconds
- Evaluation Time: 0.055 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 0.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.59%
- matrix_size_y: 1.32%
- p1: 7.24%
- p2: 0.75%
- p3: 36.17%
- p4: 22.34%
- p5: 6.19%
- p6: 6.81%
- p7: 4.34%
- p8: 4.25%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.839e-310
- Training Time: 8.577 seconds
- Evaluation Time: 0.045 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 126782022304568.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.50%
- matrix_size_y: 1.31%
- p1: 7.18%
- p2: 0.78%
- p3: 36.41%
- p4: 22.50%
- p5: 6.20%
- p6: 6.63%
- p7: 4.27%
- p8: 4.23%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.693e-310
- Training Time: 3.037 seconds
- Evaluation Time: 0.089 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.436e-310
- Training Time: 3.135 seconds
- Evaluation Time: 0.089 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.392e-310
- Training Time: 3.086 seconds
- Evaluation Time: 0.089 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.356e-310
- Training Time: 3.038 seconds
- Evaluation Time: 0.088 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.360e-310
- Training Time: 7.667 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.500e-310
- Training Time: 8.013 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.793e-310
- Training Time: 8.107 seconds
- Evaluation Time: 0.045 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.913e-310
- Training Time: 6.999 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.790e-310
- Training Time: 7.090 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.882e-310
- Training Time: 7.116 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.781e-310
- Training Time: 7.598 seconds
- Evaluation Time: 0.024 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.099e-310
- Training Time: 7.644 seconds
- Evaluation Time: 0.023 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.503e-310
- Training Time: 7.660 seconds
- Evaluation Time: 0.025 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.813e-310
- Training Time: 7.342 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.099e-310
- Training Time: 7.614 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.176e-310
- Training Time: 7.954 seconds
- Evaluation Time: 0.021 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.342e-310
- Training Time: 16.106 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.644e-310
- Training Time: 8.988 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.377e-310
- Training Time: 8.696 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.306e-310
- Training Time: 1.276 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.05%
- matrix_size_y: 1.67%
- p1: 3.45%
- p2: 0.93%
- p3: 35.70%
- p4: 27.92%
- p5: 4.86%
- p6: 14.94%
- p7: 4.45%
- p8: 3.02%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.488e-310
- Training Time: 1.279 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.05%
- matrix_size_y: 1.67%
- p1: 3.45%
- p2: 0.93%
- p3: 35.70%
- p4: 27.92%
- p5: 4.86%
- p6: 14.94%
- p7: 4.45%
- p8: 3.02%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.441e-310
- Training Time: 1.307 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.05%
- matrix_size_y: 1.67%
- p1: 3.45%
- p2: 0.93%
- p3: 35.70%
- p4: 27.92%
- p5: 4.86%
- p6: 14.94%
- p7: 4.45%
- p8: 3.02%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.675e-310
- Training Time: 2.223 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.36%
- matrix_size_y: 1.08%
- p1: 3.82%
- p2: 0.49%
- p3: 35.93%
- p4: 26.94%
- p5: 3.64%
- p6: 15.19%
- p7: 6.18%
- p8: 3.36%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.959e-310
- Training Time: 2.251 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.36%
- matrix_size_y: 1.08%
- p1: 3.82%
- p2: 0.49%
- p3: 35.93%
- p4: 26.94%
- p5: 3.64%
- p6: 15.19%
- p7: 6.18%
- p8: 3.36%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.905e-310
- Training Time: 3.423 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.36%
- matrix_size_y: 1.08%
- p1: 3.82%
- p2: 0.49%
- p3: 35.93%
- p4: 26.94%
- p5: 3.64%
- p6: 15.19%
- p7: 6.18%
- p8: 3.36%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.489e-310
- Training Time: 5.654 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.09%
- matrix_size_y: 1.23%
- p1: 3.49%
- p2: 0.31%
- p3: 35.47%
- p4: 26.59%
- p5: 3.31%
- p6: 15.72%
- p7: 6.47%
- p8: 3.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.802e-310
- Training Time: 5.634 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.09%
- matrix_size_y: 1.23%
- p1: 3.49%
- p2: 0.31%
- p3: 35.47%
- p4: 26.59%
- p5: 3.31%
- p6: 15.72%
- p7: 6.47%
- p8: 3.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.922e-310
- Training Time: 5.567 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.09%
- matrix_size_y: 1.23%
- p1: 3.49%
- p2: 0.31%
- p3: 35.47%
- p4: 26.59%
- p5: 3.31%
- p6: 15.72%
- p7: 6.47%
- p8: 3.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.935e-310
- Training Time: 8.296 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.96%
- matrix_size_y: 1.24%
- p1: 6.64%
- p2: 0.48%
- p3: 36.40%
- p4: 23.47%
- p5: 4.60%
- p6: 8.26%
- p7: 4.64%
- p8: 4.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.854e-310
- Training Time: 8.201 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.96%
- matrix_size_y: 1.24%
- p1: 6.64%
- p2: 0.48%
- p3: 36.40%
- p4: 23.47%
- p5: 4.60%
- p6: 8.26%
- p7: 4.64%
- p8: 4.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.912e-310
- Training Time: 8.309 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.96%
- matrix_size_y: 1.24%
- p1: 6.64%
- p2: 0.48%
- p3: 36.40%
- p4: 23.47%
- p5: 4.60%
- p6: 8.26%
- p7: 4.64%
- p8: 4.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.102e-310
- Training Time: 7.521 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.55%
- matrix_size_y: 1.02%
- p1: 6.84%
- p2: 0.44%
- p3: 37.56%
- p4: 22.02%
- p5: 5.31%
- p6: 7.07%
- p7: 4.55%
- p8: 4.63%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.961e-310
- Training Time: 6.991 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.55%
- matrix_size_y: 1.02%
- p1: 6.84%
- p2: 0.44%
- p3: 37.56%
- p4: 22.02%
- p5: 5.31%
- p6: 7.07%
- p7: 4.55%
- p8: 4.63%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.121e-310
- Training Time: 6.451 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.55%
- matrix_size_y: 1.02%
- p1: 6.84%
- p2: 0.44%
- p3: 37.56%
- p4: 22.02%
- p5: 5.31%
- p6: 7.07%
- p7: 4.55%
- p8: 4.63%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.736e-310
- Training Time: 11.467 seconds
- Evaluation Time: 0.020 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.680e-310
- Training Time: 9.401 seconds
- Evaluation Time: 0.023 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.128e-310
- Training Time: 9.259 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Bagging

#### Performance Metrics
- MSE: 5.032e-310
- Training Time: 13.478 seconds
- Evaluation Time: 0.216 seconds

#### Model Parameters
- criteria: 1.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 1.000

#### Feature Importance
- matrix_size_x: 7.99%
- matrix_size_y: 0.48%
- p1: 6.31%
- p2: 0.49%
- p3: 22.52%
- p4: 18.92%
- p5: 31.97%
- p6: 7.30%
- p7: 0.70%
- p8: 3.33%

---

### Bagging

#### Performance Metrics
- MSE: 5.005e-310
- Training Time: 5.038 seconds
- Evaluation Time: 0.162 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.10%
- matrix_size_y: 0.32%
- p1: 10.00%
- p2: 0.25%
- p3: 70.02%
- p4: 5.35%
- p5: 4.44%
- p6: 2.52%
- p7: 0.64%
- p8: 1.35%

---

### Bagging

#### Performance Metrics
- MSE: 5.160e-310
- Training Time: 4.691 seconds
- Evaluation Time: 0.149 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.20%
- matrix_size_y: 0.35%
- p1: 9.76%
- p2: 0.22%
- p3: 70.12%
- p4: 5.44%
- p5: 4.63%
- p6: 2.51%
- p7: 0.52%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 4.960e-310
- Training Time: 4.704 seconds
- Evaluation Time: 0.164 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.40%
- matrix_size_y: 0.35%
- p1: 9.74%
- p2: 0.22%
- p3: 70.58%
- p4: 5.31%
- p5: 4.11%
- p6: 2.45%
- p7: 0.57%
- p8: 1.28%

---

### Boosting

#### Performance Metrics
- MSE: 5.272e-310
- Training Time: 4.679 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.070
- max_depth: 15.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 75.000
- num_threads: 1.000
- use_omp: 0.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 15.19%
- matrix_size_y: 2.00%
- p1: 25.29%
- p2: 0.85%
- p3: 15.97%
- p4: 14.68%
- p5: 13.08%
- p6: 6.70%
- p7: 2.17%
- p8: 4.08%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.900e-310
- Training Time: 3.026 seconds
- Evaluation Time: 0.090 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.829e-05
- Training Time: 0.134 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.70%
- p2: 0.08%
- p3: 70.68%
- p4: 4.87%
- p5: 4.49%
- p6: 2.14%
- p7: 0.60%
- p8: 1.17%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.835e-05
- Training Time: 0.192 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.72%
- p2: 0.08%
- p3: 70.70%
- p4: 4.87%
- p5: 4.48%
- p6: 2.13%
- p7: 0.57%
- p8: 1.17%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.827e-05
- Training Time: 0.254 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.71%
- p2: 0.09%
- p3: 70.68%
- p4: 4.89%
- p5: 4.48%
- p6: 2.13%
- p7: 0.59%
- p8: 1.16%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.086 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.087 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.087 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.087 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.067 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.785e-310
- Training Time: 32.869 seconds
- Evaluation Time: 0.121 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.55%
- matrix_size_y: 0.34%
- p1: 9.83%
- p2: 0.27%
- p3: 70.07%
- p4: 5.16%
- p5: 4.43%
- p6: 2.32%
- p7: 0.65%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.251e-310
- Training Time: 26.855 seconds
- Evaluation Time: 0.120 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.40%
- matrix_size_y: 0.33%
- p1: 9.88%
- p2: 0.23%
- p3: 69.84%
- p4: 5.59%
- p5: 4.34%
- p6: 2.33%
- p7: 0.66%
- p8: 1.39%

---

### Bagging

#### Performance Metrics
- MSE: 4.761e-310
- Training Time: 24.844 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.21%
- matrix_size_y: 0.38%
- p1: 9.72%
- p2: 0.23%
- p3: 70.56%
- p4: 5.54%
- p5: 4.21%
- p6: 2.26%
- p7: 0.58%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 5.437e-310
- Training Time: 8.682 seconds
- Evaluation Time: 0.112 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.65%
- matrix_size_y: 0.33%
- p1: 9.77%
- p2: 0.27%
- p3: 70.42%
- p4: 5.32%
- p5: 3.94%
- p6: 2.34%
- p7: 0.53%
- p8: 1.42%

---

### Bagging

#### Performance Metrics
- MSE: 4.755e-310
- Training Time: 8.697 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.30%
- matrix_size_y: 0.30%
- p1: 10.44%
- p2: 0.23%
- p3: 70.01%
- p4: 5.20%
- p5: 4.51%
- p6: 2.25%
- p7: 0.52%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.111e-310
- Training Time: 8.865 seconds
- Evaluation Time: 0.133 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.13%
- matrix_size_y: 0.40%
- p1: 9.68%
- p2: 0.24%
- p3: 70.41%
- p4: 5.20%
- p5: 4.74%
- p6: 2.29%
- p7: 0.58%
- p8: 1.33%

---

### Bagging

#### Performance Metrics
- MSE: 5.055e-310
- Training Time: 6.134 seconds
- Evaluation Time: 0.137 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.23%
- matrix_size_y: 0.36%
- p1: 9.98%
- p2: 0.24%
- p3: 70.20%
- p4: 4.98%
- p5: 4.49%
- p6: 2.55%
- p7: 0.63%
- p8: 1.35%

---

### Bagging

#### Performance Metrics
- MSE: 4.891e-310
- Training Time: 6.131 seconds
- Evaluation Time: 0.135 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.51%
- matrix_size_y: 0.39%
- p1: 9.88%
- p2: 0.26%
- p3: 70.21%
- p4: 5.35%
- p5: 4.31%
- p6: 2.40%
- p7: 0.56%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.949e-310
- Training Time: 6.159 seconds
- Evaluation Time: 0.135 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.28%
- matrix_size_y: 0.38%
- p1: 9.79%
- p2: 0.19%
- p3: 70.51%
- p4: 5.39%
- p5: 4.34%
- p6: 2.41%
- p7: 0.52%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 5.302e-310
- Training Time: 5.083 seconds
- Evaluation Time: 0.141 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.58%
- matrix_size_y: 0.40%
- p1: 9.74%
- p2: 0.21%
- p3: 70.46%
- p4: 5.26%
- p5: 4.14%
- p6: 2.27%
- p7: 0.56%
- p8: 1.37%

---

### Bagging

#### Performance Metrics
- MSE: 5.497e-310
- Training Time: 5.167 seconds
- Evaluation Time: 0.141 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.50%
- matrix_size_y: 0.33%
- p1: 9.81%
- p2: 0.21%
- p3: 70.35%
- p4: 5.30%
- p5: 4.21%
- p6: 2.52%
- p7: 0.56%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 4.950e-310
- Training Time: 5.076 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.12%
- matrix_size_y: 0.31%
- p1: 9.75%
- p2: 0.27%
- p3: 70.41%
- p4: 5.58%
- p5: 4.70%
- p6: 2.14%
- p7: 0.56%
- p8: 1.17%

---

### Bagging

#### Performance Metrics
- MSE: 5.465e-310
- Training Time: 5.146 seconds
- Evaluation Time: 0.157 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.39%
- matrix_size_y: 0.36%
- p1: 9.96%
- p2: 0.23%
- p3: 70.27%
- p4: 5.25%
- p5: 4.23%
- p6: 2.46%
- p7: 0.58%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 5.377e-310
- Training Time: 5.051 seconds
- Evaluation Time: 0.148 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.37%
- matrix_size_y: 0.37%
- p1: 9.85%
- p2: 0.23%
- p3: 70.30%
- p4: 5.36%
- p5: 4.49%
- p6: 2.28%
- p7: 0.59%
- p8: 1.17%

---

### Bagging

#### Performance Metrics
- MSE: 5.268e-310
- Training Time: 4.946 seconds
- Evaluation Time: 0.162 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.64%
- matrix_size_y: 0.34%
- p1: 9.71%
- p2: 0.25%
- p3: 70.47%
- p4: 5.34%
- p5: 4.03%
- p6: 2.45%
- p7: 0.61%
- p8: 1.16%

---

### Bagging

#### Performance Metrics
- MSE: 4.668e-310
- Training Time: 5.250 seconds
- Evaluation Time: 0.168 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.63%
- matrix_size_y: 0.38%
- p1: 9.68%
- p2: 0.23%
- p3: 70.35%
- p4: 5.20%
- p5: 4.15%
- p6: 2.43%
- p7: 0.61%
- p8: 1.35%

---

### Bagging

#### Performance Metrics
- MSE: 5.362e-310
- Training Time: 5.071 seconds
- Evaluation Time: 0.156 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.34%
- matrix_size_y: 0.35%
- p1: 10.04%
- p2: 0.24%
- p3: 70.33%
- p4: 5.35%
- p5: 4.35%
- p6: 2.19%
- p7: 0.49%
- p8: 1.31%

---

### Bagging

#### Performance Metrics
- MSE: 5.502e-310
- Training Time: 5.126 seconds
- Evaluation Time: 0.163 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.36%
- matrix_size_y: 0.35%
- p1: 9.57%
- p2: 0.21%
- p3: 70.82%
- p4: 5.41%
- p5: 4.15%
- p6: 2.33%
- p7: 0.59%
- p8: 1.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.385e-310
- Training Time: 4.106 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.86%
- p1: 24.72%
- p2: 0.94%
- p3: 16.20%
- p4: 13.22%
- p5: 12.99%
- p6: 8.20%
- p7: 2.45%
- p8: 5.22%

---

### Boosting

#### Performance Metrics
- MSE: 4.748e-310
- Training Time: 3.823 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.86%
- p1: 24.72%
- p2: 0.93%
- p3: 16.21%
- p4: 13.22%
- p5: 12.98%
- p6: 8.18%
- p7: 2.45%
- p8: 5.22%

---

### Boosting

#### Performance Metrics
- MSE: 5.308e-310
- Training Time: 3.729 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.87%
- p1: 24.72%
- p2: 0.94%
- p3: 16.18%
- p4: 13.22%
- p5: 13.00%
- p6: 8.19%
- p7: 2.45%
- p8: 5.21%

---

### Boosting

#### Performance Metrics
- MSE: 5.137e-310
- Training Time: 2.924 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.125e-310
- Training Time: 2.909 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.972e-310
- Training Time: 2.906 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.155e-310
- Training Time: 2.940 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.419e-310
- Training Time: 2.940 seconds
- Evaluation Time: 0.041 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.995e-310
- Training Time: 2.946 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.412e-310
- Training Time: 2.303 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.483e-310
- Training Time: 2.423 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.850e-310
- Training Time: 2.321 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.822e-310
- Training Time: 2.299 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.276e-310
- Training Time: 2.339 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.387e-310
- Training Time: 2.331 seconds
- Evaluation Time: 0.005 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.475e-310
- Training Time: 2.310 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.270e-310
- Training Time: 2.352 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.791e-310
- Training Time: 2.333 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.220 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.836e-05
- Training Time: 0.233 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.71%
- p2: 0.08%
- p3: 70.67%
- p4: 4.89%
- p5: 4.49%
- p6: 2.16%
- p7: 0.58%
- p8: 1.16%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.845e-05
- Training Time: 0.312 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.65%
- matrix_size_y: 0.63%
- p1: 10.72%
- p2: 0.09%
- p3: 70.68%
- p4: 4.88%
- p5: 4.48%
- p6: 2.14%
- p7: 0.57%
- p8: 1.17%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.844e-05
- Training Time: 0.168 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.62%
- p1: 10.71%
- p2: 0.08%
- p3: 70.69%
- p4: 4.88%
- p5: 4.48%
- p6: 2.12%
- p7: 0.62%
- p8: 1.16%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.064 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.057 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.073 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.242e-310
- Training Time: 25.563 seconds
- Evaluation Time: 0.118 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.51%
- matrix_size_y: 0.38%
- p1: 9.78%
- p2: 0.23%
- p3: 70.19%
- p4: 5.37%
- p5: 4.42%
- p6: 2.29%
- p7: 0.55%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 5.282e-310
- Training Time: 25.387 seconds
- Evaluation Time: 0.117 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.72%
- matrix_size_y: 0.41%
- p1: 9.91%
- p2: 0.25%
- p3: 70.12%
- p4: 5.35%
- p5: 3.94%
- p6: 2.40%
- p7: 0.52%
- p8: 1.40%

---

### Bagging

#### Performance Metrics
- MSE: 4.754e-310
- Training Time: 29.355 seconds
- Evaluation Time: 0.122 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.71%
- matrix_size_y: 0.38%
- p1: 9.69%
- p2: 0.24%
- p3: 70.04%
- p4: 5.53%
- p5: 4.08%
- p6: 2.43%
- p7: 0.69%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 5.458e-310
- Training Time: 8.641 seconds
- Evaluation Time: 0.114 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.19%
- matrix_size_y: 0.34%
- p1: 10.01%
- p2: 0.24%
- p3: 70.46%
- p4: 5.26%
- p5: 4.12%
- p6: 2.56%
- p7: 0.55%
- p8: 1.28%

---

### Bagging

#### Performance Metrics
- MSE: 4.978e-310
- Training Time: 8.689 seconds
- Evaluation Time: 0.131 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.51%
- matrix_size_y: 0.31%
- p1: 10.08%
- p2: 0.22%
- p3: 70.46%
- p4: 5.20%
- p5: 4.39%
- p6: 2.21%
- p7: 0.50%
- p8: 1.13%

---

### Bagging

#### Performance Metrics
- MSE: 4.893e-310
- Training Time: 8.775 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.40%
- matrix_size_y: 0.37%
- p1: 9.96%
- p2: 0.21%
- p3: 69.94%
- p4: 5.32%
- p5: 4.74%
- p6: 2.19%
- p7: 0.61%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.742e-310
- Training Time: 6.076 seconds
- Evaluation Time: 0.150 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.57%
- matrix_size_y: 0.42%
- p1: 9.68%
- p2: 0.22%
- p3: 69.99%
- p4: 5.59%
- p5: 4.35%
- p6: 2.25%
- p7: 0.67%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 5.221e-310
- Training Time: 6.004 seconds
- Evaluation Time: 0.140 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.42%
- matrix_size_y: 0.40%
- p1: 9.82%
- p2: 0.24%
- p3: 70.45%
- p4: 5.61%
- p5: 3.85%
- p6: 2.28%
- p7: 0.63%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 4.821e-310
- Training Time: 6.046 seconds
- Evaluation Time: 0.134 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.37%
- p1: 9.63%
- p2: 0.23%
- p3: 70.51%
- p4: 5.12%
- p5: 4.21%
- p6: 2.45%
- p7: 0.44%
- p8: 1.59%

---

### Bagging

#### Performance Metrics
- MSE: 5.436e-310
- Training Time: 4.987 seconds
- Evaluation Time: 0.135 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.52%
- matrix_size_y: 0.36%
- p1: 9.81%
- p2: 0.24%
- p3: 70.45%
- p4: 5.39%
- p5: 3.85%
- p6: 2.46%
- p7: 0.57%
- p8: 1.36%

---

### Bagging

#### Performance Metrics
- MSE: 4.965e-310
- Training Time: 4.842 seconds
- Evaluation Time: 0.140 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.30%
- matrix_size_y: 0.38%
- p1: 9.75%
- p2: 0.20%
- p3: 70.13%
- p4: 5.43%
- p5: 4.51%
- p6: 2.39%
- p7: 0.55%
- p8: 1.35%

---

### Bagging

#### Performance Metrics
- MSE: 4.749e-310
- Training Time: 4.979 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.63%
- matrix_size_y: 0.33%
- p1: 9.85%
- p2: 0.29%
- p3: 70.34%
- p4: 5.31%
- p5: 4.22%
- p6: 2.33%
- p7: 0.48%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.430e-310
- Training Time: 4.732 seconds
- Evaluation Time: 0.146 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.46%
- matrix_size_y: 0.37%
- p1: 9.74%
- p2: 0.21%
- p3: 70.55%
- p4: 5.30%
- p5: 4.15%
- p6: 2.47%
- p7: 0.51%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.126e-310
- Training Time: 4.769 seconds
- Evaluation Time: 0.149 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.48%
- matrix_size_y: 0.30%
- p1: 9.68%
- p2: 0.25%
- p3: 70.34%
- p4: 5.34%
- p5: 4.41%
- p6: 2.35%
- p7: 0.54%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 4.646e-310
- Training Time: 4.848 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.47%
- matrix_size_y: 0.35%
- p1: 10.00%
- p2: 0.25%
- p3: 70.04%
- p4: 5.31%
- p5: 4.26%
- p6: 2.28%
- p7: 0.69%
- p8: 1.35%

---

### Bagging

#### Performance Metrics
- MSE: 5.357e-310
- Training Time: 4.690 seconds
- Evaluation Time: 0.154 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.61%
- matrix_size_y: 0.36%
- p1: 10.07%
- p2: 0.20%
- p3: 70.03%
- p4: 5.19%
- p5: 4.27%
- p6: 2.44%
- p7: 0.60%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.215e-310
- Training Time: 4.709 seconds
- Evaluation Time: 0.151 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.10%
- matrix_size_y: 0.38%
- p1: 9.87%
- p2: 0.25%
- p3: 70.23%
- p4: 5.21%
- p5: 4.67%
- p6: 2.26%
- p7: 0.61%
- p8: 1.42%

---

### Bagging

#### Performance Metrics
- MSE: 4.970e-310
- Training Time: 5.384 seconds
- Evaluation Time: 0.161 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.55%
- matrix_size_y: 0.36%
- p1: 9.96%
- p2: 0.22%
- p3: 70.10%
- p4: 5.39%
- p5: 4.19%
- p6: 2.45%
- p7: 0.55%
- p8: 1.21%

---

### Boosting

#### Performance Metrics
- MSE: 4.695e-310
- Training Time: 3.337 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.86%
- p1: 24.72%
- p2: 0.93%
- p3: 16.21%
- p4: 13.22%
- p5: 12.99%
- p6: 8.19%
- p7: 2.44%
- p8: 5.22%

---

### Boosting

#### Performance Metrics
- MSE: 5.291e-310
- Training Time: 3.507 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.86%
- p1: 24.72%
- p2: 0.94%
- p3: 16.20%
- p4: 13.21%
- p5: 13.01%
- p6: 8.19%
- p7: 2.45%
- p8: 5.21%

---

### Boosting

#### Performance Metrics
- MSE: 4.708e-310
- Training Time: 4.260 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.87%
- p1: 24.72%
- p2: 0.94%
- p3: 16.21%
- p4: 13.21%
- p5: 12.99%
- p6: 8.19%
- p7: 2.45%
- p8: 5.21%

---

### Boosting

#### Performance Metrics
- MSE: 5.467e-310
- Training Time: 2.876 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.790e-310
- Training Time: 2.911 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.119e-310
- Training Time: 2.912 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.100e-310
- Training Time: 2.940 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.392e-310
- Training Time: 2.935 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.941e-310
- Training Time: 2.921 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.716e-310
- Training Time: 2.270 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.242e-310
- Training Time: 2.308 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.904e-310
- Training Time: 2.276 seconds
- Evaluation Time: 0.004 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.704e-310
- Training Time: 2.253 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.394e-310
- Training Time: 2.310 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.223e-310
- Training Time: 2.282 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.410e-310
- Training Time: 2.320 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.924e-310
- Training Time: 2.328 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.241e-310
- Training Time: 2.345 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.218 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.214 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.222 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.218 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.219 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.764e-310
- Training Time: 3.045 seconds
- Evaluation Time: 0.088 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.662e-310
- Training Time: 3.141 seconds
- Evaluation Time: 0.089 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.827e-05
- Training Time: 0.146 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.72%
- p2: 0.09%
- p3: 70.68%
- p4: 4.87%
- p5: 4.48%
- p6: 2.15%
- p7: 0.58%
- p8: 1.17%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.848e-05
- Training Time: 0.148 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.64%
- matrix_size_y: 0.63%
- p1: 10.72%
- p2: 0.09%
- p3: 70.68%
- p4: 4.87%
- p5: 4.48%
- p6: 2.14%
- p7: 0.57%
- p8: 1.18%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.699e-05
- Training Time: 0.123 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.65%
- matrix_size_y: 0.63%
- p1: 10.71%
- p2: 0.08%
- p3: 70.70%
- p4: 4.88%
- p5: 4.48%
- p6: 2.12%
- p7: 0.57%
- p8: 1.16%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.085 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.061 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.059 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.062 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.060 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 4.799e-310
- Training Time: 23.455 seconds
- Evaluation Time: 0.117 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.43%
- matrix_size_y: 0.33%
- p1: 9.85%
- p2: 0.24%
- p3: 70.12%
- p4: 5.42%
- p5: 4.41%
- p6: 2.52%
- p7: 0.61%
- p8: 1.09%

---

### Bagging

#### Performance Metrics
- MSE: 4.923e-310
- Training Time: 23.288 seconds
- Evaluation Time: 0.116 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.72%
- matrix_size_y: 0.33%
- p1: 9.93%
- p2: 0.30%
- p3: 70.33%
- p4: 5.21%
- p5: 4.11%
- p6: 2.27%
- p7: 0.54%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.961e-310
- Training Time: 23.739 seconds
- Evaluation Time: 0.119 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.49%
- matrix_size_y: 0.39%
- p1: 9.66%
- p2: 0.24%
- p3: 70.08%
- p4: 5.40%
- p5: 4.40%
- p6: 2.47%
- p7: 0.60%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 4.973e-310
- Training Time: 8.611 seconds
- Evaluation Time: 0.109 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.43%
- matrix_size_y: 0.32%
- p1: 9.77%
- p2: 0.25%
- p3: 70.46%
- p4: 5.32%
- p5: 4.21%
- p6: 2.31%
- p7: 0.61%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 4.668e-310
- Training Time: 8.700 seconds
- Evaluation Time: 0.111 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.37%
- matrix_size_y: 0.33%
- p1: 9.85%
- p2: 0.24%
- p3: 70.31%
- p4: 5.43%
- p5: 4.23%
- p6: 2.31%
- p7: 0.62%
- p8: 1.31%

---

### Bagging

#### Performance Metrics
- MSE: 5.391e-310
- Training Time: 8.627 seconds
- Evaluation Time: 0.110 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.39%
- matrix_size_y: 0.41%
- p1: 9.58%
- p2: 0.22%
- p3: 70.62%
- p4: 5.41%
- p5: 4.34%
- p6: 2.25%
- p7: 0.55%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.268e-310
- Training Time: 6.014 seconds
- Evaluation Time: 0.136 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.74%
- matrix_size_y: 0.29%
- p1: 10.02%
- p2: 0.24%
- p3: 69.97%
- p4: 5.32%
- p5: 3.97%
- p6: 2.72%
- p7: 0.53%
- p8: 1.20%

---

### Bagging

#### Performance Metrics
- MSE: 4.734e-310
- Training Time: 5.970 seconds
- Evaluation Time: 0.130 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.00%
- matrix_size_y: 0.34%
- p1: 10.40%
- p2: 0.28%
- p3: 70.17%
- p4: 5.03%
- p5: 4.59%
- p6: 2.23%
- p7: 0.55%
- p8: 1.41%

---

### Bagging

#### Performance Metrics
- MSE: 4.780e-310
- Training Time: 6.035 seconds
- Evaluation Time: 0.130 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.59%
- matrix_size_y: 0.41%
- p1: 9.99%
- p2: 0.20%
- p3: 70.34%
- p4: 5.18%
- p5: 4.33%
- p6: 2.29%
- p7: 0.56%
- p8: 1.11%

---

### Bagging

#### Performance Metrics
- MSE: 5.281e-310
- Training Time: 4.734 seconds
- Evaluation Time: 0.137 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.84%
- matrix_size_y: 0.36%
- p1: 10.18%
- p2: 0.25%
- p3: 70.72%
- p4: 5.30%
- p5: 4.51%
- p6: 2.12%
- p7: 0.60%
- p8: 1.12%

---

### Bagging

#### Performance Metrics
- MSE: 5.072e-310
- Training Time: 4.817 seconds
- Evaluation Time: 0.138 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.30%
- matrix_size_y: 0.38%
- p1: 9.68%
- p2: 0.20%
- p3: 70.51%
- p4: 5.35%
- p5: 4.31%
- p6: 2.35%
- p7: 0.63%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 5.020e-310
- Training Time: 4.732 seconds
- Evaluation Time: 0.132 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.34%
- matrix_size_y: 0.35%
- p1: 9.74%
- p2: 0.21%
- p3: 70.54%
- p4: 5.55%
- p5: 4.43%
- p6: 2.12%
- p7: 0.56%
- p8: 1.16%

---

### Bagging

#### Performance Metrics
- MSE: 4.931e-310
- Training Time: 4.651 seconds
- Evaluation Time: 0.145 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.28%
- matrix_size_y: 0.35%
- p1: 9.91%
- p2: 0.24%
- p3: 70.26%
- p4: 5.46%
- p5: 4.13%
- p6: 2.51%
- p7: 0.58%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 4.700e-310
- Training Time: 4.670 seconds
- Evaluation Time: 0.144 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.27%
- matrix_size_y: 0.36%
- p1: 9.85%
- p2: 0.23%
- p3: 70.25%
- p4: 5.52%
- p5: 4.06%
- p6: 2.59%
- p7: 0.63%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.084e-310
- Training Time: 4.687 seconds
- Evaluation Time: 0.143 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.27%
- matrix_size_y: 0.37%
- p1: 9.80%
- p2: 0.26%
- p3: 70.14%
- p4: 5.40%
- p5: 4.56%
- p6: 2.35%
- p7: 0.56%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 5.284e-310
- Training Time: 4.634 seconds
- Evaluation Time: 0.147 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.45%
- matrix_size_y: 0.40%
- p1: 9.72%
- p2: 0.26%
- p3: 70.20%
- p4: 5.39%
- p5: 4.23%
- p6: 2.41%
- p7: 0.64%
- p8: 1.28%

---

### Bagging

#### Performance Metrics
- MSE: 5.471e-310
- Training Time: 4.639 seconds
- Evaluation Time: 0.149 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.48%
- matrix_size_y: 0.33%
- p1: 9.85%
- p2: 0.21%
- p3: 70.29%
- p4: 5.32%
- p5: 4.20%
- p6: 2.49%
- p7: 0.57%
- p8: 1.26%

---

### Bagging

#### Performance Metrics
- MSE: 5.238e-310
- Training Time: 4.654 seconds
- Evaluation Time: 0.146 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.57%
- matrix_size_y: 0.37%
- p1: 9.87%
- p2: 0.21%
- p3: 70.30%
- p4: 5.17%
- p5: 4.28%
- p6: 2.44%
- p7: 0.56%
- p8: 1.23%

---

### Boosting

#### Performance Metrics
- MSE: 5.461e-310
- Training Time: 3.313 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.87%
- p1: 24.72%
- p2: 0.94%
- p3: 16.19%
- p4: 13.22%
- p5: 12.99%
- p6: 8.18%
- p7: 2.44%
- p8: 5.22%

---

### Boosting

#### Performance Metrics
- MSE: 4.691e-310
- Training Time: 3.276 seconds
- Evaluation Time: 0.006 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.87%
- p1: 24.73%
- p2: 0.94%
- p3: 16.20%
- p4: 13.22%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.21%

---

### Boosting

#### Performance Metrics
- MSE: 5.443e-310
- Training Time: 3.344 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.22%
- matrix_size_y: 1.86%
- p1: 24.71%
- p2: 0.95%
- p3: 16.21%
- p4: 13.22%
- p5: 12.99%
- p6: 8.18%
- p7: 2.44%
- p8: 5.22%

---

### Boosting

#### Performance Metrics
- MSE: 4.703e-310
- Training Time: 2.866 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.041e-310
- Training Time: 2.864 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.804e-310
- Training Time: 2.897 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.763e-310
- Training Time: 2.917 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.876e-310
- Training Time: 2.891 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.337e-310
- Training Time: 2.893 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.920e-310
- Training Time: 2.248 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.361e-310
- Training Time: 2.251 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.285e-310
- Training Time: 2.281 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.481e-310
- Training Time: 2.315 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.037e-310
- Training Time: 2.334 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.907e-310
- Training Time: 2.282 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.006e-310
- Training Time: 2.272 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.001e-310
- Training Time: 2.370 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.645e-310
- Training Time: 2.322 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.039 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.219 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.821e-310
- Training Time: 3.104 seconds
- Evaluation Time: 0.089 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.894e-310
- Training Time: 3.099 seconds
- Evaluation Time: 0.088 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.976e-310
- Training Time: 3.039 seconds
- Evaluation Time: 0.087 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.476e-310
- Training Time: 8.073 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.311e-310
- Training Time: 8.061 seconds
- Evaluation Time: 0.045 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.466e-310
- Training Time: 8.021 seconds
- Evaluation Time: 0.045 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.268e-310
- Training Time: 7.075 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.176e-310
- Training Time: 7.129 seconds
- Evaluation Time: 0.030 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.809e-310
- Training Time: 7.065 seconds
- Evaluation Time: 0.031 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.121e-310
- Training Time: 7.671 seconds
- Evaluation Time: 0.023 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.677e-310
- Training Time: 7.729 seconds
- Evaluation Time: 0.024 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.642e-310
- Training Time: 7.579 seconds
- Evaluation Time: 0.023 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.156e-310
- Training Time: 7.027 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.666e-310
- Training Time: 7.034 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.200e-310
- Training Time: 7.087 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.257e-310
- Training Time: 8.393 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.386e-310
- Training Time: 7.998 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.489e-310
- Training Time: 8.087 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.862e-04
- Training Time: 0.074 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.98%
- matrix_size_y: 0.32%
- p1: 2.16%
- p2: 0.73%
- p3: 74.47%
- p4: 5.87%
- p5: 1.17%
- p6: 11.73%
- p7: 1.17%
- p8: 1.39%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.928e-04
- Training Time: 0.072 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.96%
- matrix_size_y: 0.28%
- p1: 2.16%
- p2: 0.75%
- p3: 74.46%
- p4: 5.89%
- p5: 1.17%
- p6: 11.75%
- p7: 1.17%
- p8: 1.40%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 4.927e-04
- Training Time: 0.064 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 1.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.96%
- matrix_size_y: 0.30%
- p1: 2.19%
- p2: 0.75%
- p3: 74.37%
- p4: 5.88%
- p5: 1.16%
- p6: 11.94%
- p7: 1.06%
- p8: 1.37%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.054e-04
- Training Time: 0.027 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 1.93%
- matrix_size_y: 0.39%
- p1: 2.72%
- p2: 0.32%
- p3: 78.35%
- p4: 7.28%
- p5: 1.28%
- p6: 6.25%
- p7: 0.56%
- p8: 0.92%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.538e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.90%
- matrix_size_y: 0.31%
- p1: 2.08%
- p2: 0.23%
- p3: 79.84%
- p4: 7.44%
- p5: 1.01%
- p6: 6.65%
- p7: 0.71%
- p8: 0.84%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.538e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.90%
- matrix_size_y: 0.31%
- p1: 2.08%
- p2: 0.23%
- p3: 79.84%
- p4: 7.44%
- p5: 1.01%
- p6: 6.65%
- p7: 0.71%
- p8: 0.84%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.538e-04
- Training Time: 0.042 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 2.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 0.90%
- matrix_size_y: 0.31%
- p1: 2.08%
- p2: 0.23%
- p3: 79.84%
- p4: 7.44%
- p5: 1.01%
- p6: 6.65%
- p7: 0.71%
- p8: 0.84%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.041 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.047 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 1.172e-04
- Training Time: 0.040 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.18%
- matrix_size_y: 0.27%
- p1: 9.12%
- p2: 0.14%
- p3: 75.30%
- p4: 4.58%
- p5: 2.40%
- p6: 2.11%
- p7: 0.63%
- p8: 1.27%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 8.546e-05
- Training Time: 0.054 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.54%
- matrix_size_y: 0.20%
- p1: 10.01%
- p2: 0.22%
- p3: 71.13%
- p4: 4.93%
- p5: 4.22%
- p6: 1.91%
- p7: 0.98%
- p8: 1.85%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 8.546e-05
- Training Time: 0.048 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.54%
- matrix_size_y: 0.20%
- p1: 10.01%
- p2: 0.22%
- p3: 71.13%
- p4: 4.93%
- p5: 4.22%
- p6: 1.91%
- p7: 0.98%
- p8: 1.85%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 8.546e-05
- Training Time: 0.049 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.54%
- matrix_size_y: 0.20%
- p1: 10.01%
- p2: 0.22%
- p3: 71.13%
- p4: 4.93%
- p5: 4.22%
- p6: 1.91%
- p7: 0.98%
- p8: 1.85%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.063 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Arbre de décision simple

#### Performance Metrics
- MSE: 3.846e-05
- Training Time: 0.058 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- num_threads: 4.000
- use_omp: 1.000

#### Feature Importance
- matrix_size_x: 4.63%
- matrix_size_y: 0.62%
- p1: 10.72%
- p2: 0.09%
- p3: 70.71%
- p4: 4.89%
- p5: 4.48%
- p6: 2.15%
- p7: 0.57%
- p8: 1.14%

---

### Bagging

#### Performance Metrics
- MSE: 5.147e-310
- Training Time: 11.093 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.28%
- matrix_size_y: 0.38%
- p1: 3.15%
- p2: 0.58%
- p3: 77.37%
- p4: 5.53%
- p5: 0.98%
- p6: 8.97%
- p7: 0.65%
- p8: 1.10%

---

### Bagging

#### Performance Metrics
- MSE: 5.446e-310
- Training Time: 10.995 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.40%
- matrix_size_y: 0.35%
- p1: 3.46%
- p2: 0.39%
- p3: 76.19%
- p4: 5.57%
- p5: 0.87%
- p6: 9.92%
- p7: 0.76%
- p8: 1.08%

---

### Bagging

#### Performance Metrics
- MSE: 4.797e-310
- Training Time: 11.104 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.35%
- matrix_size_y: 0.39%
- p1: 3.32%
- p2: 0.48%
- p3: 77.14%
- p4: 5.24%
- p5: 0.92%
- p6: 9.45%
- p7: 0.73%
- p8: 0.99%

---

### Bagging

#### Performance Metrics
- MSE: 5.381e-310
- Training Time: 2.797 seconds
- Evaluation Time: 0.036 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.77%
- matrix_size_y: 0.40%
- p1: 3.22%
- p2: 0.33%
- p3: 78.24%
- p4: 6.60%
- p5: 1.23%
- p6: 6.01%
- p7: 0.99%
- p8: 1.22%

---

### Bagging

#### Performance Metrics
- MSE: 4.806e-310
- Training Time: 2.691 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 2.02%
- matrix_size_y: 0.38%
- p1: 2.75%
- p2: 0.36%
- p3: 75.39%
- p4: 6.71%
- p5: 1.07%
- p6: 9.59%
- p7: 0.82%
- p8: 0.93%

---

### Bagging

#### Performance Metrics
- MSE: 5.497e-310
- Training Time: 2.707 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.69%
- matrix_size_y: 0.31%
- p1: 3.29%
- p2: 0.42%
- p3: 76.61%
- p4: 6.01%
- p5: 0.88%
- p6: 9.00%
- p7: 0.82%
- p8: 0.98%

---

### Bagging

#### Performance Metrics
- MSE: 5.235e-310
- Training Time: 3.003 seconds
- Evaluation Time: 0.069 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.35%
- matrix_size_y: 0.55%
- p1: 2.42%
- p2: 0.36%
- p3: 78.66%
- p4: 6.17%
- p5: 1.54%
- p6: 7.06%
- p7: 0.79%
- p8: 1.09%

---

### Bagging

#### Performance Metrics
- MSE: 4.850e-310
- Training Time: 2.941 seconds
- Evaluation Time: 0.070 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.45%
- matrix_size_y: 0.34%
- p1: 3.64%
- p2: 0.42%
- p3: 77.79%
- p4: 5.11%
- p5: 1.31%
- p6: 7.61%
- p7: 1.04%
- p8: 1.30%

---

### Bagging

#### Performance Metrics
- MSE: 5.218e-310
- Training Time: 2.977 seconds
- Evaluation Time: 0.074 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 1.40%
- matrix_size_y: 0.36%
- p1: 3.17%
- p2: 0.31%
- p3: 78.42%
- p4: 5.80%
- p5: 1.16%
- p6: 7.41%
- p7: 0.86%
- p8: 1.11%

---

### Bagging

#### Performance Metrics
- MSE: 5.418e-310
- Training Time: 3.220 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 3.80%
- matrix_size_y: 0.43%
- p1: 10.20%
- p2: 0.27%
- p3: 72.29%
- p4: 4.76%
- p5: 3.16%
- p6: 2.73%
- p7: 0.81%
- p8: 1.54%

---

### Bagging

#### Performance Metrics
- MSE: 4.882e-310
- Training Time: 3.204 seconds
- Evaluation Time: 0.095 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.03%
- matrix_size_y: 0.43%
- p1: 10.22%
- p2: 0.23%
- p3: 72.48%
- p4: 4.43%
- p5: 3.38%
- p6: 2.42%
- p7: 0.93%
- p8: 1.45%

---

### Bagging

#### Performance Metrics
- MSE: 5.081e-310
- Training Time: 3.183 seconds
- Evaluation Time: 0.093 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.11%
- matrix_size_y: 0.43%
- p1: 10.80%
- p2: 0.26%
- p3: 71.10%
- p4: 4.83%
- p5: 3.44%
- p6: 2.83%
- p7: 0.90%
- p8: 1.31%

---

### Bagging

#### Performance Metrics
- MSE: 4.790e-310
- Training Time: 3.900 seconds
- Evaluation Time: 0.129 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.02%
- matrix_size_y: 0.33%
- p1: 9.73%
- p2: 0.27%
- p3: 69.90%
- p4: 5.15%
- p5: 4.31%
- p6: 3.09%
- p7: 0.73%
- p8: 1.47%

---

### Bagging

#### Performance Metrics
- MSE: 5.489e-310
- Training Time: 3.923 seconds
- Evaluation Time: 0.125 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.83%
- matrix_size_y: 0.34%
- p1: 9.62%
- p2: 0.24%
- p3: 70.63%
- p4: 4.72%
- p5: 3.84%
- p6: 2.54%
- p7: 0.73%
- p8: 1.50%

---

### Bagging

#### Performance Metrics
- MSE: 5.243e-310
- Training Time: 3.928 seconds
- Evaluation Time: 0.126 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 4.87%
- matrix_size_y: 0.37%
- p1: 10.08%
- p2: 0.28%
- p3: 70.64%
- p4: 5.00%
- p5: 4.26%
- p6: 2.50%
- p7: 0.76%
- p8: 1.24%

---

### Bagging

#### Performance Metrics
- MSE: 5.337e-310
- Training Time: 4.640 seconds
- Evaluation Time: 0.146 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.37%
- matrix_size_y: 0.36%
- p1: 10.05%
- p2: 0.22%
- p3: 70.06%
- p4: 5.28%
- p5: 4.34%
- p6: 2.43%
- p7: 0.65%
- p8: 1.23%

---

### Bagging

#### Performance Metrics
- MSE: 4.678e-310
- Training Time: 4.638 seconds
- Evaluation Time: 0.147 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.25%
- matrix_size_y: 0.36%
- p1: 9.79%
- p2: 0.24%
- p3: 70.34%
- p4: 5.47%
- p5: 4.31%
- p6: 2.35%
- p7: 0.61%
- p8: 1.27%

---

### Bagging

#### Performance Metrics
- MSE: 5.380e-310
- Training Time: 4.696 seconds
- Evaluation Time: 0.147 seconds

#### Model Parameters
- criteria: 0.000
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 2.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.16%
- matrix_size_y: 0.37%
- p1: 9.82%
- p2: 0.25%
- p3: 70.32%
- p4: 5.33%
- p5: 4.18%
- p6: 2.52%
- p7: 0.74%
- p8: 1.31%

---

### Boosting

#### Performance Metrics
- MSE: 5.468e-310
- Training Time: 1.361 seconds
- Evaluation Time: 0.000 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.185e-310
- Training Time: 1.321 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 4.646e-310
- Training Time: 1.289 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 1.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 0.00%
- matrix_size_y: 0.00%
- p1: 0.00%
- p2: 0.00%
- p3: 0.00%
- p4: 0.00%
- p5: 0.00%
- p6: 0.00%
- p7: 0.00%
- p8: 0.00%

---

### Boosting

#### Performance Metrics
- MSE: 5.319e-310
- Training Time: 0.818 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 4.788e-310
- Training Time: 0.821 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 5.143e-310
- Training Time: 0.819 seconds
- Evaluation Time: 0.001 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.047
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 2.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 6.62%
- matrix_size_y: 1.19%
- p1: 10.02%
- p2: 1.00%
- p3: 31.37%
- p4: 20.82%
- p5: 5.69%
- p6: 17.68%
- p7: 1.70%
- p8: 3.91%

---

### Boosting

#### Performance Metrics
- MSE: 4.878e-310
- Training Time: 1.423 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 1.41%
- p1: 8.87%
- p2: 1.06%
- p3: 34.54%
- p4: 20.82%
- p5: 5.86%
- p6: 16.57%
- p7: 2.22%
- p8: 3.33%

---

### Boosting

#### Performance Metrics
- MSE: 4.690e-310
- Training Time: 1.420 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 1.41%
- p1: 8.87%
- p2: 1.06%
- p3: 34.54%
- p4: 20.82%
- p5: 5.86%
- p6: 16.57%
- p7: 2.22%
- p8: 3.33%

---

### Boosting

#### Performance Metrics
- MSE: 4.948e-310
- Training Time: 1.410 seconds
- Evaluation Time: 0.022 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.048
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 3.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 5.32%
- matrix_size_y: 1.41%
- p1: 8.87%
- p2: 1.06%
- p3: 34.54%
- p4: 20.82%
- p5: 5.86%
- p6: 16.57%
- p7: 2.22%
- p8: 3.33%

---

### Boosting

#### Performance Metrics
- MSE: 4.967e-310
- Training Time: 1.502 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.136e-310
- Training Time: 1.544 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 4.916e-310
- Training Time: 1.513 seconds
- Evaluation Time: 0.002 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.040
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 4.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 11.74%
- matrix_size_y: 1.47%
- p1: 25.79%
- p2: 0.86%
- p3: 19.58%
- p4: 12.34%
- p5: 11.47%
- p6: 8.97%
- p7: 2.05%
- p8: 5.73%

---

### Boosting

#### Performance Metrics
- MSE: 5.388e-310
- Training Time: 1.874 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.96%
- matrix_size_y: 1.53%
- p1: 23.98%
- p2: 1.10%
- p3: 16.08%
- p4: 12.79%
- p5: 11.82%
- p6: 9.08%
- p7: 2.84%
- p8: 5.81%

---

### Boosting

#### Performance Metrics
- MSE: 4.814e-310
- Training Time: 1.870 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.96%
- matrix_size_y: 1.53%
- p1: 23.98%
- p2: 1.10%
- p3: 16.08%
- p4: 12.79%
- p5: 11.82%
- p6: 9.08%
- p7: 2.84%
- p8: 5.81%

---

### Boosting

#### Performance Metrics
- MSE: 5.094e-310
- Training Time: 1.863 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.039
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 5.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.96%
- matrix_size_y: 1.53%
- p1: 23.98%
- p2: 1.10%
- p3: 16.08%
- p4: 12.79%
- p5: 11.82%
- p6: 9.08%
- p7: 2.84%
- p8: 5.81%

---

### Boosting

#### Performance Metrics
- MSE: 5.420e-310
- Training Time: 2.335 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 5.281e-310
- Training Time: 2.315 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### Boosting

#### Performance Metrics
- MSE: 4.656e-310
- Training Time: 2.289 seconds
- Evaluation Time: 0.003 seconds

#### Model Parameters
- criteria: 0.000
- initial_prediction: 0.037
- learning_rate: 0.100
- max_depth: 10.000
- min_impurity_decrease: 0.000
- min_samples_split: 3.000
- n_estimators: 200.000
- num_threads: 6.000
- use_omp: 1.000
- which_loss_function: 0.000

#### Feature Importance
- matrix_size_x: 14.21%
- matrix_size_y: 1.80%
- p1: 24.79%
- p2: 1.01%
- p3: 16.19%
- p4: 13.21%
- p5: 12.98%
- p6: 8.18%
- p7: 2.44%
- p8: 5.20%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.078 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 82.53%
- F1: 11.02%
- F2: 605.25%
- F3: 472.79%
- F4: 69.95%
- F5: 306.25%
- F6: 113.29%
- F7: 53.57%
- F8: 68.71%
- F9: 32.71%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.078 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 82.53%
- F1: 11.02%
- F2: 605.25%
- F3: 472.79%
- F4: 69.95%
- F5: 306.25%
- F6: 113.29%
- F7: 53.57%
- F8: 68.71%
- F9: 32.71%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.078 seconds
- Evaluation Time: 0.011 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 82.53%
- F1: 11.02%
- F2: 605.25%
- F3: 472.79%
- F4: 69.95%
- F5: 306.25%
- F6: 113.29%
- F7: 53.57%
- F8: 68.71%
- F9: 32.71%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.109 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 160.19%
- F1: 16.07%
- F2: 1227.50%
- F3: 910.90%
- F4: 129.91%
- F5: 537.95%
- F6: 281.95%
- F7: 124.86%
- F8: 174.97%
- F9: 58.92%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.109 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 160.19%
- F1: 16.07%
- F2: 1227.50%
- F3: 910.90%
- F4: 129.91%
- F5: 537.95%
- F6: 281.95%
- F7: 124.86%
- F8: 174.97%
- F9: 58.92%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.109 seconds
- Evaluation Time: 0.018 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 160.19%
- F1: 16.07%
- F2: 1227.50%
- F3: 910.90%
- F4: 129.91%
- F5: 537.95%
- F6: 281.95%
- F7: 124.86%
- F8: 174.97%
- F9: 58.92%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.139 seconds
- Evaluation Time: 0.026 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 219.63%
- F1: 18.85%
- F2: 1870.00%
- F3: 1419.06%
- F4: 181.00%
- F5: 833.56%
- F6: 451.52%
- F7: 204.51%
- F8: 296.68%
- F9: 84.40%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.138 seconds
- Evaluation Time: 0.025 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 219.63%
- F1: 18.85%
- F2: 1870.00%
- F3: 1419.06%
- F4: 181.00%
- F5: 833.56%
- F6: 451.52%
- F7: 204.51%
- F8: 296.68%
- F9: 84.40%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.138 seconds
- Evaluation Time: 0.026 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 219.63%
- F1: 18.85%
- F2: 1870.00%
- F3: 1419.06%
- F4: 181.00%
- F5: 833.56%
- F6: 451.52%
- F7: 204.51%
- F8: 296.68%
- F9: 84.40%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.162 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 542.66%
- F1: 25.02%
- F2: 2038.44%
- F3: 1377.65%
- F4: 225.67%
- F5: 531.45%
- F6: 369.85%
- F7: 211.25%
- F8: 584.44%
- F9: 98.01%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.162 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 542.66%
- F1: 25.02%
- F2: 2038.44%
- F3: 1377.65%
- F4: 225.67%
- F5: 531.45%
- F6: 369.85%
- F7: 211.25%
- F8: 584.44%
- F9: 98.01%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.162 seconds
- Evaluation Time: 0.029 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 542.66%
- F1: 25.02%
- F2: 2038.44%
- F3: 1377.65%
- F4: 225.67%
- F5: 531.45%
- F6: 369.85%
- F7: 211.25%
- F8: 584.44%
- F9: 98.01%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.191 seconds
- Evaluation Time: 0.034 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 710.03%
- F1: 32.04%
- F2: 2409.05%
- F3: 1621.46%
- F4: 307.92%
- F5: 540.53%
- F6: 405.56%
- F7: 252.77%
- F8: 790.20%
- F9: 106.93%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.192 seconds
- Evaluation Time: 0.034 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 710.03%
- F1: 32.04%
- F2: 2409.05%
- F3: 1621.46%
- F4: 307.92%
- F5: 540.53%
- F6: 405.56%
- F7: 252.77%
- F8: 790.20%
- F9: 106.93%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.191 seconds
- Evaluation Time: 0.034 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 710.03%
- F1: 32.04%
- F2: 2409.05%
- F3: 1621.46%
- F4: 307.92%
- F5: 540.53%
- F6: 405.56%
- F7: 252.77%
- F8: 790.20%
- F9: 106.93%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.216 seconds
- Evaluation Time: 0.038 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### LightGBM

#### Performance Metrics
- MSE: 6.953e-310
- Training Time: 0.217 seconds
- Evaluation Time: 0.037 seconds

#### Model Parameters
- colsample_bytree: 0.800
- learning_rate: 0.100
- max_depth: 10.000
- n_estimators: 200.000
- num_leaves: 31.000
- subsample: 0.800

#### Feature Importance
- F0: 866.81%
- F1: 28.74%
- F2: 2693.91%
- F3: 1793.54%
- F4: 394.61%
- F5: 593.19%
- F6: 460.27%
- F7: 242.60%
- F8: 881.01%
- F9: 119.98%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.983e-310
- Training Time: 1.274 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.05%
- matrix_size_y: 1.67%
- p1: 3.45%
- p2: 0.93%
- p3: 35.70%
- p4: 27.92%
- p5: 4.86%
- p6: 14.94%
- p7: 4.45%
- p8: 3.02%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.247e-310
- Training Time: 1.272 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.05%
- matrix_size_y: 1.67%
- p1: 3.45%
- p2: 0.93%
- p3: 35.70%
- p4: 27.92%
- p5: 4.86%
- p6: 14.94%
- p7: 4.45%
- p8: 3.02%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.911e-310
- Training Time: 1.277 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.05%
- matrix_size_y: 1.67%
- p1: 3.45%
- p2: 0.93%
- p3: 35.70%
- p4: 27.92%
- p5: 4.86%
- p6: 14.94%
- p7: 4.45%
- p8: 3.02%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.365e-310
- Training Time: 5.631 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.36%
- matrix_size_y: 1.08%
- p1: 3.82%
- p2: 0.49%
- p3: 35.93%
- p4: 26.94%
- p5: 3.64%
- p6: 15.19%
- p7: 6.18%
- p8: 3.36%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.801e-310
- Training Time: 5.587 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.36%
- matrix_size_y: 1.08%
- p1: 3.82%
- p2: 0.49%
- p3: 35.93%
- p4: 26.94%
- p5: 3.64%
- p6: 15.19%
- p7: 6.18%
- p8: 3.36%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.099e-310
- Training Time: 5.501 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 3.36%
- matrix_size_y: 1.08%
- p1: 3.82%
- p2: 0.49%
- p3: 35.93%
- p4: 26.94%
- p5: 3.64%
- p6: 15.19%
- p7: 6.18%
- p8: 3.36%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.787e-310
- Training Time: 4.907 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.09%
- matrix_size_y: 1.23%
- p1: 3.49%
- p2: 0.31%
- p3: 35.47%
- p4: 26.59%
- p5: 3.31%
- p6: 15.72%
- p7: 6.47%
- p8: 3.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.257e-310
- Training Time: 4.983 seconds
- Evaluation Time: 0.015 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.09%
- matrix_size_y: 1.23%
- p1: 3.49%
- p2: 0.31%
- p3: 35.47%
- p4: 26.59%
- p5: 3.31%
- p6: 15.72%
- p7: 6.47%
- p8: 3.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.918e-310
- Training Time: 4.900 seconds
- Evaluation Time: 0.014 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 4.09%
- matrix_size_y: 1.23%
- p1: 3.49%
- p2: 0.31%
- p3: 35.47%
- p4: 26.59%
- p5: 3.31%
- p6: 15.72%
- p7: 6.47%
- p8: 3.34%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.637e-310
- Training Time: 8.288 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.96%
- matrix_size_y: 1.24%
- p1: 6.64%
- p2: 0.48%
- p3: 36.40%
- p4: 23.47%
- p5: 4.60%
- p6: 8.26%
- p7: 4.64%
- p8: 4.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.132e-310
- Training Time: 8.232 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.96%
- matrix_size_y: 1.24%
- p1: 6.64%
- p2: 0.48%
- p3: 36.40%
- p4: 23.47%
- p5: 4.60%
- p6: 8.26%
- p7: 4.64%
- p8: 4.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.983e-310
- Training Time: 8.243 seconds
- Evaluation Time: 0.019 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 4.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 9.96%
- matrix_size_y: 1.24%
- p1: 6.64%
- p2: 0.48%
- p3: 36.40%
- p4: 23.47%
- p5: 4.60%
- p6: 8.26%
- p7: 4.64%
- p8: 4.32%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.638e-310
- Training Time: 6.494 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.55%
- matrix_size_y: 1.02%
- p1: 6.84%
- p2: 0.44%
- p3: 37.56%
- p4: 22.02%
- p5: 5.31%
- p6: 7.07%
- p7: 4.55%
- p8: 4.63%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.001e-310
- Training Time: 6.527 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.55%
- matrix_size_y: 1.02%
- p1: 6.84%
- p2: 0.44%
- p3: 37.56%
- p4: 22.02%
- p5: 5.31%
- p6: 7.07%
- p7: 4.55%
- p8: 4.63%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.852e-310
- Training Time: 6.483 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 5.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.55%
- matrix_size_y: 1.02%
- p1: 6.84%
- p2: 0.44%
- p3: 37.56%
- p4: 22.02%
- p5: 5.31%
- p6: 7.07%
- p7: 4.55%
- p8: 4.63%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.682e-310
- Training Time: 7.988 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.104e-310
- Training Time: 8.020 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.390e-310
- Training Time: 8.440 seconds
- Evaluation Time: 0.017 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.164e-310
- Training Time: 3.063 seconds
- Evaluation Time: 0.089 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.873e-310
- Training Time: 3.134 seconds
- Evaluation Time: 0.090 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.272e-310
- Training Time: 3.084 seconds
- Evaluation Time: 0.088 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.336e-310
- Training Time: 8.205 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.173e-310
- Training Time: 7.719 seconds
- Evaluation Time: 0.032 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 3.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.85%
- matrix_size_y: 1.08%
- p1: 7.36%
- p2: 0.44%
- p3: 36.69%
- p4: 22.72%
- p5: 5.64%
- p6: 6.96%
- p7: 4.27%
- p8: 4.00%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.718e-310
- Training Time: 7.459 seconds
- Evaluation Time: 0.046 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 2.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.58%
- matrix_size_y: 1.13%
- p1: 7.25%
- p2: 0.43%
- p3: 36.91%
- p4: 22.88%
- p5: 5.88%
- p6: 6.64%
- p7: 4.00%
- p8: 4.31%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.778e-310
- Training Time: 7.845 seconds
- Evaluation Time: 0.024 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 10.58%
- matrix_size_y: 1.13%
- p1: 7.25%
- p2: 0.43%
- p3: 36.91%
- p4: 22.88%
- p5: 5.88%
- p6: 6.64%
- p7: 4.00%
- p8: 4.31%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.471e-310
- Training Time: 12.527 seconds
- Evaluation Time: 0.016 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 14.77%
- matrix_size_y: 0.23%
- p1: 6.45%
- p2: 0.13%
- p3: 48.81%
- p4: 18.26%
- p5: 8.13%
- p6: 1.36%
- p7: 0.52%
- p8: 1.35%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 4.754e-310
- Training Time: 12.200 seconds
- Evaluation Time: 0.067 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 1.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 14.77%
- matrix_size_y: 0.23%
- p1: 6.45%
- p2: 0.13%
- p3: 48.81%
- p4: 18.26%
- p5: 8.13%
- p6: 1.36%
- p7: 0.52%
- p8: 1.35%

---

### Advanced GBDT

#### Performance Metrics
- MSE: 5.081e-310
- Training Time: 12.177 seconds
- Evaluation Time: 0.013 seconds

#### Model Parameters
- binning_method: 1.000
- learning_rate: 0.100
- max_depth: 10.000
- min_data_leaf: 20.000
- n_estimators: 200.000
- num_bins: 255.000
- num_threads: 6.000
- use_dart: 0.000

#### Feature Importance
- matrix_size_x: 14.77%
- matrix_size_y: 0.23%
- p1: 6.45%
- p2: 0.13%
- p3: 48.81%
- p4: 18.26%
- p5: 8.13%
- p6: 1.36%
- p7: 0.52%
- p8: 1.35%

---

